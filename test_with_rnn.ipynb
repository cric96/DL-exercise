{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/test_with_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji2Yp08lPMHJ"
   },
   "source": [
    "# Neural Networks applied in Aggregate Computing\n",
    "In this notebook, I tried to apply Neural Network and Recurrent Neural Networks (RNN) in the context of Aggregate Computing (AC).\n",
    "\n",
    "## Model\n",
    "\n",
    "Usually, RNN are trained in indipendent sequences. In case of Aggregate Computing, the temporal sequence are correlated with each other following a neighbourhood policy. \n",
    "\n",
    "The key idea here is:\n",
    "- express the system as a graph. Offline we can imagine to access to the entire system\n",
    "- in each time step, we aggregate data from the neighbours and then we use RNN to compute the right output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tihJbe7wP_L7"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ld4IkeCHdg9f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXGw5707Rv7"
   },
   "source": [
    "# Simple Graph\n",
    "\n",
    "In this model, I model graph as:\n",
    "$G = (N, E)$\n",
    "\n",
    "Where, $N$ contains a feature vector and an output vector.\n",
    "\n",
    "$E$ is expressed as adjacency matrix, so: $E_{i,j} = 1$ iff $i$ is neighbour of $j$.\n",
    "\n",
    "Input is a matrix contains the concatenation of feature vector and output vector, something like: $ I(n) = <f(n), o(n)>$.\n",
    "Where $<a, b, c>$ means the column-wise fector concatenation. \n",
    "For instance, giving a vector $a = [1, 2]$ and $b = [2, 3]$, $<a,b> = [1, 2, 2, 3]$.\n",
    "\n",
    "The neighbour aggregation data can be computed leveraging matrix multiplication --- so increasing traning performance.\n",
    "$$ reduction(E * F) $$\n",
    "Where F contains all node features.\n",
    "$reduction$ is a multiset function (e.g. summation, mean,...).\n",
    "\n",
    "Pay attention, this model can be easly used in a decentralized situation.\n",
    "Indeed, the data aggregation will be done without global adjency matrix but only retrieving neighbour data. The dense layer already works locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "DaicADIO7U34"
   },
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "input = tf.concat([feature, output], axis = 1)\n",
    "input = input[:,tf.newaxis, :]\n",
    "\n",
    "neigh = tf.constant([\n",
    "                     [n, 1, n, n], \n",
    "                     [1, n, 1, n],\n",
    "                     [n, 1, n, 1],\n",
    "                     [n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "ground = tf.constant([\n",
    "                     [0], \n",
    "                     [1],\n",
    "                     [2],\n",
    "                     [3],\n",
    "                    ], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRY-rUZ27Y0E"
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "Taking the output of previous step, adjecency matrix, and feature vector, this function compute the value of the next evaluation.\n",
    "So\n",
    "1. compute neighbourhood feature via aggregation\n",
    "2. concat neighbourhood feature with local feature and previous output\n",
    "3. perform a forward pass of a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "UKorlgUN7arq"
   },
   "outputs": [],
   "source": [
    "def forward(result, neigh, feature, model, log_enable=False):\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  reshape = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  neigh_evaluation = tf.reduce_min(tf.multiply(neigh, reshape), 1) ## pass reduction strategy\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, feature.shape[:2]) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJqP660S5W4"
   },
   "source": [
    "# Model creation\n",
    "Create a sequential model given layers and the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CdXR3Tb3TV8l"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, layers):\n",
    "  input_layer = tf.keras.layers.InputLayer(input_shape=input_shape[1:], batch_size=input_shape[0])\n",
    "  layers.insert(0, input_layer)\n",
    "  return tf.keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOdTAPsnGEf"
   },
   "source": [
    "## Recurrent model\n",
    "Simple network creation with multiple recurrent layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8oNvEE-Bh4B1"
   },
   "outputs": [],
   "source": [
    "def instantiate_layers(output_count = 1):\n",
    "  return [\n",
    "    tf.keras.layers.GRU(units = 4, activation='relu', return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.GRU(units = output_count, activation='relu', return_sequences=False, stateful=True, bias_initializer='ones'),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLAigDrToouO"
   },
   "source": [
    "## Linear Model\n",
    "Simple network with multiple linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9DneyuoJoltR"
   },
   "outputs": [],
   "source": [
    "def instantiate_linear_layers(output_count = 1):\n",
    "  return [\n",
    "    tf.keras.layers.Dense(units = 16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 8, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = output_count, activation='relu', bias_initializer='ones')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2iXarjQrq10"
   },
   "source": [
    "## Model instatiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JFidlC53rvyL"
   },
   "outputs": [],
   "source": [
    "linear = \"linear\"\n",
    "recurrent = \"recurrent\"\n",
    "same = \"same\"\n",
    "\n",
    "def instatiate(input, mode = \"same\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return create_model(input.shape, instantiate_linear_layers(output_count))\n",
    "  elif mode == recurrent:\n",
    "    return create_model(input.shape, instantiate_layers(output_count))\n",
    "\n",
    "def copy_model(model, mode = \"same\", input = \"\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return model\n",
    "  elif mode == recurrent:\n",
    "    change_model = instatiate(input, recurrent, output_count)\n",
    "    change_model.set_weights(model.get_weights())\n",
    "    return change_model\n",
    "mode = linear\n",
    "model = instatiate(input, linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZquNuutUD-n"
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "xvzeO1W3UGi4"
   },
   "outputs": [],
   "source": [
    "## TODO pass input and network\n",
    "def train(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each=100, verbose=False):\n",
    "  input, neigh, feature, ground = data\n",
    "  for j in range(iteration):\n",
    "    with tf.GradientTape() as tape:\n",
    "      result = input\n",
    "      to_backprop = 0\n",
    "      for i in range(stabilise_in):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "      for i in range(stabilisation_check):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "        to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
    "      model.reset_states()\n",
    "      \n",
    "      gradient = tape.gradient(to_backprop, model.weights)\n",
    "      optimizer.apply_gradients(zip(gradient, model.weights))\n",
    "    if(j % each == 0):\n",
    "      if(verbose):\n",
    "        partial_result = result[:, 0, 1:2]\n",
    "        tf.print(\"Ground truth: \\n\", tf.reshape(ground, ground.shape[0]))\n",
    "        tf.print(\"Current prediciton \\n\", tf.reshape(partial_result, result.shape[0]))\n",
    "        tf.print(\"Full output \\n\", result)\n",
    "      \n",
    "      print(\"Epoch \", j ,\"Loss = \", tf.reduce_sum(to_backprop).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFGPPgD_hdHi"
   },
   "source": [
    "\n",
    "## Train loop\n",
    "Here I want only to find a function that overfits, so it solve this specific problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56wyzp3MdzYy",
    "outputId": "16270c05-acb3-40a5-cd24-f5a114f12706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss =  5.618208\n",
      "Epoch  50 Loss =  3.8985057\n",
      "Epoch  100 Loss =  2.0568602\n",
      "Epoch  150 Loss =  0.51155466\n",
      "Epoch  200 Loss =  0.05412233\n",
      "Epoch  250 Loss =  0.006758415\n",
      "Epoch  300 Loss =  0.0030281323\n",
      "Epoch  350 Loss =  0.0023959447\n",
      "Epoch  400 Loss =  0.0026372876\n",
      "Epoch  450 Loss =  0.0030181608\n",
      "Epoch  500 Loss =  0.0034021153\n",
      "Epoch  550 Loss =  0.0050702016\n",
      "Epoch  600 Loss =  0.0067576747\n",
      "Epoch  650 Loss =  0.0013892739\n",
      "Epoch  700 Loss =  0.000451607\n",
      "Epoch  750 Loss =  0.00015032403\n",
      "Epoch  800 Loss =  4.7090678e-05\n",
      "Epoch  850 Loss =  0.07242025\n",
      "Epoch  900 Loss =  0.05615524\n",
      "Epoch  950 Loss =  0.04536298\n",
      "Epoch  1000 Loss =  0.04049966\n",
      "Epoch  1050 Loss =  0.038068235\n",
      "Epoch  1100 Loss =  0.036590878\n",
      "Epoch  1150 Loss =  0.035115395\n",
      "Epoch  1200 Loss =  0.033584524\n",
      "Epoch  1250 Loss =  0.032018617\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-896c1a053095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-fa8d416e0794>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mto_backprop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstabilisation_check\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-bafbd662006b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(result, neigh, feature, model, log_enable)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mreshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mneigh_evaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## pass reduction strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_evaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1023\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1024\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_autopacking_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m   \u001b[0;34m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mas_ref\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_should_not_autopack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m   \u001b[0minferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_from_nested_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_should_not_autopack\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1506\u001b[0m   \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m   \u001b[0;31m# TODO(slebedev): add nest.all?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_NON_AUTOPACKABLE_TYPES\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m   \u001b[0;31m# pylint: enable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "model = instatiate(input, mode) ## comment to avoid the recomputation of weights\n",
    "\n",
    "iteration = 2000\n",
    "stabilise_in = 2\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data = (input, neigh, feature, ground)\n",
    "train(model, forward, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "Check the model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.        0.553976 ]]\n",
      "\n",
      " [[0.        1.0857401]]\n",
      "\n",
      " [[0.        1.0857401]]\n",
      "\n",
      " [[0.        1.0857401]]], shape=(4, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = input\n",
    "for i in range(2):\n",
    "  result = forward(result, neigh, feature, model)\n",
    "print(result)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_dense_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqbsEJEnWOc7"
   },
   "source": [
    "# Check result, generalisation\n",
    "In this part, I try to use the same network in another graph, to see if it can be used in different graphs.\n",
    "\n",
    "## Linear network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LDTXF5knmGv",
    "outputId": "00d048a0-6c41-42d8-b33f-a721c8a66ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.        1.1871182]]\n",
      "\n",
      " [[0.        1.3581653]]\n",
      "\n",
      " [[0.        1.3921162]]\n",
      "\n",
      " [[0.        1.399143 ]]\n",
      "\n",
      " [[0.        1.3996701]]], shape=(5, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0]\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n]\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, n, n, n], \n",
    "                     [1, n, 1, n, n],\n",
    "                     [n, 1, n, 1, n],\n",
    "                     [n, n, 1, n, 1],\n",
    "                     [n, n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states()\n",
    "for i in range(4):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, 1, n], \n",
    "                     [1, n, n, 1],\n",
    "                     [1, n, n, 1],\n",
    "                     [n, 1, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states() ## if has recurrent layers\n",
    "for i in range(2):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(tf.constant([[0, 100]]))) ## should be ~ 101\n",
    "print(model(tf.constant([[0, 10]]))) ## should be ~ 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced graph data\n",
    "In this case, we suppose to have a collective state that will evolve accordingly the node execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "feature_state = tf.constant([[1],[0],[0],[0]], dtype=tf.float32)\n",
    "output_state = tf.constant([[0],[n],[n],[n]], dtype=tf.float32)\n",
    "state = tf.constant([[0],[0],[0],[0]], dtype=tf.float32)\n",
    "#state = tf.random.uniform((8, 1), minval=0, maxval=1)\n",
    "\n",
    "input_state = tf.concat([feature_state, output_state, state], axis = 1)\n",
    "input_state = input_state[:,tf.newaxis, :]\n",
    "\n",
    "neigh_state = tf.constant([\n",
    "                     [n, 1, n, n],\n",
    "                     [1, n, 1, n],\n",
    "                     [n, 1, n, 1],\n",
    "                     [n, n, 1, n]\n",
    "                    ], dtype=tf.float32)\n",
    "ground_state = tf.constant([[0],[1],[2],[3]], dtype=tf.float32)\n",
    "## normalisation\n",
    "# feature_state = feature_state / n\n",
    "# output_state = output_state / n\n",
    "# neigh_state = neigh_state / n\n",
    "# ground_state = ground_state / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass rivisited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_state(result, neigh, feature, model_eval, log_enable=False):\n",
    "  input_shape_data = result[:, :, 1:]\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  old_output = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  old_state = tf.reshape(result[:,:,2], feature.shape[0])\n",
    "  max_value = tf.reduce_max(neigh)\n",
    "  neigh_with_zero = tf.where(neigh == max_value, 0.0, 1.0)\n",
    "  neigh_output_evaluation = tf.reduce_min(tf.multiply(neigh, old_output), 1) ## pass reduction strategy\n",
    "  neigh_state_evaluation = tf.reduce_sum(tf.multiply(neigh_with_zero, old_state), 1) ## state evolution strategy\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_output_evaluation[:, tf.newaxis], neigh_state_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model_eval(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, (input_shape_data.shape[0], input_shape_data.shape[2])) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.744017601 0.847516596 0.865683258 1.00766766]\n",
      "Full output \n",
      " [[[1 0.744017601 1.00143075]]\n",
      "\n",
      " [[0 0.847516596 1.00442922]]\n",
      "\n",
      " [[0 0.865683258 0.999147832]]\n",
      "\n",
      " [[0 1.00766766 1.0463928]]]\n",
      "Epoch  0 Loss =  5.832711\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.312663794 1.1858381 1.35088348 1.20530963]\n",
      "Full output \n",
      " [[[1 0.312663794 1.3992821]]\n",
      "\n",
      " [[0 1.1858381 0.952123523]]\n",
      "\n",
      " [[0 1.35088348 1.13881898]]\n",
      "\n",
      " [[0 1.20530963 1.10157347]]]\n",
      "Epoch  50 Loss =  3.774544\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.151855707 1.36951458 1.84292841 1.73007667]\n",
      "Full output \n",
      " [[[1 0.151855707 1.69233215]]\n",
      "\n",
      " [[0 1.36951458 1.15353513]]\n",
      "\n",
      " [[0 1.84292841 1.43383014]]\n",
      "\n",
      " [[0 1.73007667 1.34738517]]]\n",
      "Epoch  100 Loss =  1.7968051\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.243330419 1.40868688 2.19076133 2.34219766]\n",
      "Full output \n",
      " [[[1 0.243330419 1.72881305]]\n",
      "\n",
      " [[0 1.40868688 1.07939732]]\n",
      "\n",
      " [[0 2.19076133 1.50950706]]\n",
      "\n",
      " [[0 2.34219766 1.50494123]]]\n",
      "Epoch  150 Loss =  0.69206625\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0809122324 1.21556294 2.03108501 2.37262964]\n",
      "Full output \n",
      " [[[1 0.0809122324 1.62302542]]\n",
      "\n",
      " [[0 1.21556294 0.912837386]]\n",
      "\n",
      " [[0 2.03108501 1.35094714]]\n",
      "\n",
      " [[0 2.37262964 1.44275212]]]\n",
      "Epoch  200 Loss =  0.44691935\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.22780824 1.24123061 1.27304578]\n",
      "Full output \n",
      " [[[1 0 1.36073363]]\n",
      "\n",
      " [[0 1.22780824 0.887290239]]\n",
      "\n",
      " [[0 1.24123061 0.916695833]]\n",
      "\n",
      " [[0 1.27304578 0.986395717]]]\n",
      "Epoch  250 Loss =  3.6095328\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.46662962 1.45538962 1.4374311]\n",
      "Full output \n",
      " [[[1 0 1.49382854]]\n",
      "\n",
      " [[0 1.46662962 0.914277613]]\n",
      "\n",
      " [[0 1.45538962 0.946223795]]\n",
      "\n",
      " [[0 1.4374311 1.00935698]]]\n",
      "Epoch  300 Loss =  2.9559727\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.68210661 1.65559697 1.60040045]\n",
      "Full output \n",
      " [[[1 0 1.49363232]]\n",
      "\n",
      " [[0 1.68210661 0.963634729]]\n",
      "\n",
      " [[0 1.65559697 0.985433102]]\n",
      "\n",
      " [[0 1.60040045 1.03082049]]]\n",
      "Epoch  350 Loss =  2.5427604\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.72947669 1.71332443 1.67173839]\n",
      "Full output \n",
      " [[[1 0 1.43730819]]\n",
      "\n",
      " [[0 1.72947669 0.994463146]]\n",
      "\n",
      " [[0 1.71332443 1.01029408]]\n",
      "\n",
      " [[0 1.67173839 1.05105269]]]\n",
      "Epoch  400 Loss =  2.3785932\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.70949316 1.70830905 1.70473969]\n",
      "Full output \n",
      " [[[1 0 1.3861196]]\n",
      "\n",
      " [[0 1.70949316 0.99767375]]\n",
      "\n",
      " [[0 1.70830905 1.01199055]]\n",
      "\n",
      " [[0 1.70473969 1.05514574]]]\n",
      "Epoch  450 Loss =  2.266163\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.74718285 1.75485122 1.77831054]\n",
      "Full output \n",
      " [[[1 0 1.39511657]]\n",
      "\n",
      " [[0 1.74718285 1.00353885]]\n",
      "\n",
      " [[0 1.75485122 1.01919317]]\n",
      "\n",
      " [[0 1.77831054 1.06708372]]]\n",
      "Epoch  500 Loss =  2.1108394\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.68805814 1.71885204 1.79647839]\n",
      "Full output \n",
      " [[[1 0 1.43030238]]\n",
      "\n",
      " [[0 1.68805814 0.96543]]\n",
      "\n",
      " [[0 1.71885204 0.988689]]\n",
      "\n",
      " [[0 1.79647839 1.04732072]]]\n",
      "Epoch  550 Loss =  2.00095\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.170033216 1.73429179 2.56177616 2.66047335]\n",
      "Full output \n",
      " [[[1 0.170033216 1.54552412]]\n",
      "\n",
      " [[0 1.73429179 0.93771112]]\n",
      "\n",
      " [[0 2.56177616 1.30264628]]\n",
      "\n",
      " [[0 2.66047335 1.33812416]]]\n",
      "Epoch  600 Loss =  0.9972631\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0 1.59706497 1.76507187 1.94177723]\n",
      "Full output \n",
      " [[[1 0 1.82063818]]\n",
      "\n",
      " [[0 1.59706497 0.8295753]]\n",
      "\n",
      " [[0 1.76507187 0.923319042]]\n",
      "\n",
      " [[0 1.94177723 1.02092934]]]\n",
      "Epoch  650 Loss =  1.5321386\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0878330469 1.51728618 2.42446232 2.72848439]\n",
      "Full output \n",
      " [[[1 0.0878330469 1.79285049]]\n",
      "\n",
      " [[0 1.51728618 0.801475286]]\n",
      "\n",
      " [[0 2.42446232 1.21703315]]\n",
      "\n",
      " [[0 2.72848439 1.2416594]]]\n",
      "Epoch  700 Loss =  0.569252\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.133404732 1.25619459 2.20424151 2.75977516]\n",
      "Full output \n",
      " [[[1 0.133404732 1.83890319]]\n",
      "\n",
      " [[0 1.25619459 0.705360115]]\n",
      "\n",
      " [[0 2.20424151 1.14821494]]\n",
      "\n",
      " [[0 2.75977516 1.19626904]]]\n",
      "Epoch  750 Loss =  0.20479766\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0606851578 1.0642395 2.13025212 2.86774373]\n",
      "Full output \n",
      " [[[1 0.0606851578 1.95949459]]\n",
      "\n",
      " [[0 1.0642395 0.667242169]]\n",
      "\n",
      " [[0 2.13025212 1.16681576]]\n",
      "\n",
      " [[0 2.86774373 1.30434787]]]\n",
      "Epoch  800 Loss =  0.06744783\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0430247784 1.01396537 2.08201647 2.91842794]\n",
      "Full output \n",
      " [[[1 0.0430247784 1.9883436]]\n",
      "\n",
      " [[0 1.01396537 0.655080914]]\n",
      "\n",
      " [[0 2.08201647 1.15335894]]\n",
      "\n",
      " [[0 2.91842794 1.33998132]]]\n",
      "Epoch  850 Loss =  0.03813353\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0540101528 1.00116682 2.0671072 2.96160769]\n",
      "Full output \n",
      " [[[1 0.0540101528 2.00134134]]\n",
      "\n",
      " [[0 1.00116682 0.65650636]]\n",
      "\n",
      " [[0 2.0671072 1.14739716]]\n",
      "\n",
      " [[0 2.96160769 1.35391104]]]\n",
      "Epoch  900 Loss =  0.029498914\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0615073442 0.98856622 2.04220533 2.97583151]\n",
      "Full output \n",
      " [[[1 0.0615073442 2.01400232]]\n",
      "\n",
      " [[0 0.98856622 0.661287606]]\n",
      "\n",
      " [[0 2.04220533 1.14352322]]\n",
      "\n",
      " [[0 2.97583151 1.3694247]]]\n",
      "Epoch  950 Loss =  0.02661115\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0580005646 0.985099077 2.03587723 2.990839]\n",
      "Full output \n",
      " [[[1 0.0580005646 2.02337551]]\n",
      "\n",
      " [[0 0.985099077 0.65607667]]\n",
      "\n",
      " [[0 2.03587723 1.13837624]]\n",
      "\n",
      " [[0 2.990839 1.36952496]]]\n",
      "Epoch  1000 Loss =  0.023560949\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.098115325 1.0049715 2.05486822 3.0134511]\n",
      "Full output \n",
      " [[[1 0.098115325 2.02549434]]\n",
      "\n",
      " [[0 1.0049715 0.662950456]]\n",
      "\n",
      " [[0 2.05486822 1.14027798]]\n",
      "\n",
      " [[0 3.0134511 1.39177656]]]\n",
      "Epoch  1050 Loss =  0.030814763\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0603362322 0.981465042 2.01190853 2.99084568]\n",
      "Full output \n",
      " [[[1 0.0603362322 2.04201579]]\n",
      "\n",
      " [[0 0.981465042 0.658289552]]\n",
      "\n",
      " [[0 2.01190853 1.13475311]]\n",
      "\n",
      " [[0 2.99084568 1.3787421]]]\n",
      "Epoch  1100 Loss =  0.022501932\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0527126789 0.983135 2.02090645 3.00535297]\n",
      "Full output \n",
      " [[[1 0.0527126789 2.05335855]]\n",
      "\n",
      " [[0 0.983135 0.645945787]]\n",
      "\n",
      " [[0 2.02090645 1.13109505]]\n",
      "\n",
      " [[0 3.00535297 1.37180495]]]\n",
      "Epoch  1150 Loss =  0.020324975\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0526348352 0.976625443 1.99844432 2.98915696]\n",
      "Full output \n",
      " [[[1 0.0526348352 2.06228399]]\n",
      "\n",
      " [[0 0.976625443 0.648544252]]\n",
      "\n",
      " [[0 1.99844432 1.12803841]]\n",
      "\n",
      " [[0 2.98915696 1.3766942]]]\n",
      "Epoch  1200 Loss =  0.020536069\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0422800779 0.981859 2.00483036 2.9973]\n",
      "Full output \n",
      " [[[1 0.0422800779 2.06857395]]\n",
      "\n",
      " [[0 0.981859 0.640736222]]\n",
      "\n",
      " [[0 2.00483036 1.12393391]]\n",
      "\n",
      " [[0 2.9973 1.36553657]]]\n",
      "Epoch  1250 Loss =  0.017669972\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.223661423 1.06864095 2.09021974 3.03615808]\n",
      "Full output \n",
      " [[[1 0.223661423 2.05861092]]\n",
      "\n",
      " [[0 1.06864095 0.675488353]]\n",
      "\n",
      " [[0 2.09021974 1.1539278]]\n",
      "\n",
      " [[0 3.03615808 1.37944937]]]\n",
      "Epoch  1300 Loss =  0.082367875\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0673391819 0.993228436 2.00766397 2.97658348]\n",
      "Full output \n",
      " [[[1 0.0673391819 2.10183096]]\n",
      "\n",
      " [[0 0.993228436 0.606378794]]\n",
      "\n",
      " [[0 2.00766397 1.1153326]]\n",
      "\n",
      " [[0 2.97658348 1.35247719]]]\n",
      "Epoch  1350 Loss =  0.019014485\n",
      "Ground truth: \n",
      " [0 1 2 3]\n",
      "Current prediciton \n",
      " [0.0437877178 0.983246386 2.00792718 2.99505019]\n",
      "Full output \n",
      " [[[1 0.0437877178 2.1212604]]\n",
      "\n",
      " [[0 0.983246386 0.590754807]]\n",
      "\n",
      " [[0 2.00792718 1.11095929]]\n",
      "\n",
      " [[0 2.99505019 1.3522594]]]\n",
      "Epoch  1400 Loss =  0.0154640805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fa408071db25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_with_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-0cf54f6d4cde>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meach\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BiasAddGrad\u001b[0;34m(op, received_grad)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   return (received_grad,\n\u001b[0;32m--> 351\u001b[0;31m           gen_nn_ops.bias_add_grad(\n\u001b[0m\u001b[1;32m    352\u001b[0m               out_backprop=received_grad, data_format=data_format))\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add_grad\u001b[0;34m(out_backprop, data_format, name)\u001b[0m\n\u001b[1;32m    747\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    750\u001b[0m         _ctx, \"BiasAddGrad\", name, out_backprop, \"data_format\", data_format)\n\u001b[1;32m    751\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "model_state = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
    "iteration = 2000\n",
    "stabilise_in = 4\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data_state = (input_state, neigh_state, feature_state, ground_state)\n",
    "train(model_state, forward_with_state, data_state, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)\n",
    "\n",
    "result = input_state\n",
    "for i in range(10):\n",
    "  result = forward_with_state(result, neigh_state, feature_state, model_state)\n",
    "print(result)\n",
    "model_state.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.        4.4675436 1.7458205]]\n",
      "\n",
      " [[0.        4.3244076 1.6575043]]\n",
      "\n",
      " [[0.        4.299906  1.6525524]]\n",
      "\n",
      " [[0.        4.4896474 1.7541965]]], shape=(4, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = input_state\n",
    "for i in range(10):\n",
    "  result = forward_with_state(result, neigh_state, feature_state, model_state, False)\n",
    "  \n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9O5CIu3uDdkZ/uIe7V0gL",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "test-with-rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
