{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/test_with_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji2Yp08lPMHJ"
   },
   "source": [
    "# Neural Networks applied in Aggregate Computing\n",
    "In this notebook, I tried to apply Neural Network and Recurrent Neural Networks (RNN) in the context of Aggregate Computing (AC).\n",
    "\n",
    "## Model\n",
    "\n",
    "Usually, RNN are trained in indipendent sequences. In case of Aggregate Computing, the temporal sequence are correlated with each other following a neighbourhood policy. \n",
    "\n",
    "The key idea here is:\n",
    "- express the system as a graph. Offline we can imagine to access to the entire system\n",
    "- in each time step, we aggregate data from the neighbours and then we use RNN to compute the right output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tihJbe7wP_L7"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ld4IkeCHdg9f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXGw5707Rv7"
   },
   "source": [
    "# Simple Graph\n",
    "\n",
    "In this model, I model graph as:\n",
    "$G = (N, E)$\n",
    "\n",
    "Where, $N$ contains a feature vector and an output vector.\n",
    "\n",
    "$E$ is expressed as adjacency matrix, so: $E_{i,j} = 1$ iff $i$ is neighbour of $j$.\n",
    "\n",
    "Input is a matrix contains the concatenation of feature vector and output vector, something like: $ I(n) = <f(n), o(n)>$.\n",
    "Where $<a, b, c>$ means the column-wise fector concatenation. \n",
    "For instance, giving a vector $a = [1, 2]$ and $b = [2, 3]$, $<a,b> = [1, 2, 2, 3]$.\n",
    "\n",
    "The neighbour aggregation data can be computed leveraging matrix multiplication --- so increasing traning performance.\n",
    "$$ reduction(E * F) $$\n",
    "Where F contains all node features.\n",
    "$reduction$ is a multiset function (e.g. summation, mean,...).\n",
    "\n",
    "Pay attention, this model can be easly used in a decentralized situation.\n",
    "Indeed, the data aggregation will be done without global adjency matrix but only retrieving neighbour data. The dense layer already works locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DaicADIO7U34"
   },
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "input = tf.concat([feature, output], axis = 1)\n",
    "input = input[:,tf.newaxis, :]\n",
    "\n",
    "neigh = tf.constant([\n",
    "                     [n, 1, n, n], \n",
    "                     [1, n, 1, n],\n",
    "                     [n, 1, n, 1],\n",
    "                     [n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "ground = tf.constant([\n",
    "                     [0], \n",
    "                     [1],\n",
    "                     [2],\n",
    "                     [3],\n",
    "                    ], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRY-rUZ27Y0E"
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "Taking the output of previous step, adjecency matrix, and feature vector, this function compute the value of the next evaluation.\n",
    "So\n",
    "1. compute neighbourhood feature via aggregation\n",
    "2. concat neighbourhood feature with local feature and previous output\n",
    "3. perform a forward pass of a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UKorlgUN7arq"
   },
   "outputs": [],
   "source": [
    "def forward(result, neigh, feature, model, log_enable=False):\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  reshape = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  neigh_evaluation = tf.reduce_min(tf.multiply(neigh, reshape), 1) ## pass reduction strategy\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, feature.shape[:2]) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJqP660S5W4"
   },
   "source": [
    "# Model creation\n",
    "Create a sequential model given layers and the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CdXR3Tb3TV8l"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, layers):\n",
    "  input_layer = tf.keras.layers.InputLayer(input_shape=input_shape[1:], batch_size=input_shape[0])\n",
    "  layers.insert(0, input_layer)\n",
    "  return tf.keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOdTAPsnGEf"
   },
   "source": [
    "## Recurrent model\n",
    "Simple network creation with multiple recurrent layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8oNvEE-Bh4B1"
   },
   "outputs": [],
   "source": [
    "def instantiate_layers(output_count = 1):\n",
    "  return [\n",
    "    tf.keras.layers.GRU(units = 4, activation='relu', return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.GRU(units = output_count, activation='relu', return_sequences=False, stateful=True, bias_initializer='ones'),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLAigDrToouO"
   },
   "source": [
    "## Linear Model\n",
    "Simple network with multiple linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9DneyuoJoltR"
   },
   "outputs": [],
   "source": [
    "def instantiate_linear_layers(output_count = 1):\n",
    "  return [\n",
    "    tf.keras.layers.Dense(units = 32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 8, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 4, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = output_count, activation='relu', kernel_initializer='lecun_normal',bias_initializer='ones')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2iXarjQrq10"
   },
   "source": [
    "## Model instatiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JFidlC53rvyL"
   },
   "outputs": [],
   "source": [
    "linear = \"linear\"\n",
    "recurrent = \"recurrent\"\n",
    "same = \"same\"\n",
    "\n",
    "def instatiate(input, mode = \"same\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return create_model(input.shape, instantiate_linear_layers(output_count))\n",
    "  elif mode == recurrent:\n",
    "    return create_model(input.shape, instantiate_layers(output_count))\n",
    "\n",
    "def copy_model(model, mode = \"same\", input = \"\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return model\n",
    "  elif mode == recurrent:\n",
    "    change_model = instatiate(input, recurrent, output_count)\n",
    "    change_model.set_weights(model.get_weights())\n",
    "    return change_model\n",
    "mode = linear\n",
    "model = instatiate(input, linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZquNuutUD-n"
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xvzeO1W3UGi4"
   },
   "outputs": [],
   "source": [
    "## TODO pass input and network\n",
    "def train(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each=100, verbose=False, store=False):\n",
    "  input, neigh, feature, ground = data\n",
    "  for j in range(iteration):\n",
    "    with tf.GradientTape() as tape:\n",
    "      result = input\n",
    "      to_backprop = 0\n",
    "      for i in range(stabilise_in):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "      for i in range(stabilisation_check):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "        to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
    "      model.reset_states()\n",
    "      \n",
    "      gradient = tape.gradient(to_backprop, model.weights)\n",
    "      optimizer.apply_gradients(zip(gradient, model.weights))\n",
    "    if(j % each == 0):\n",
    "      if(verbose == True):\n",
    "        partial_result = result[:, 0, 1:2]\n",
    "        tf.print(\"Ground truth: \\n\", tf.reshape(ground, ground.shape[0]))\n",
    "        tf.print(\"Current prediciton \\n\", tf.reshape(partial_result, result.shape[0]))\n",
    "        tf.print(\"Full output \\n\", result)\n",
    "      if(store):\n",
    "        model.save('epoch/model_dense_' + str(j))\n",
    "      print(\"Epoch \", j ,\"Loss = \", tf.reduce_sum(to_backprop).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFGPPgD_hdHi"
   },
   "source": [
    "\n",
    "## Train loop\n",
    "Here I want only to find a function that overfits, so it solve this specific problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56wyzp3MdzYy",
    "outputId": "16270c05-acb3-40a5-cd24-f5a114f12706"
   },
   "outputs": [],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "model = instatiate(input, mode) ## comment to avoid the recomputation of weights\n",
    "\n",
    "iteration = 2000\n",
    "stabilise_in = 2\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data = (input, neigh, feature, ground)\n",
    "train(model, forward, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "Check the model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = input\n",
    "for i in range(10):\n",
    "  result = forward(result, neigh, feature, model)\n",
    "print(result)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_dense_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqbsEJEnWOc7"
   },
   "source": [
    "# Check result, generalisation\n",
    "In this part, I try to use the same network in another graph, to see if it can be used in different graphs.\n",
    "\n",
    "## Linear network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LDTXF5knmGv",
    "outputId": "00d048a0-6c41-42d8-b33f-a721c8a66ee6"
   },
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0]\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n]\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, n, n, n], \n",
    "                     [1, n, 1, n, n],\n",
    "                     [n, 1, n, 1, n],\n",
    "                     [n, n, 1, n, 1],\n",
    "                     [n, n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states()\n",
    "for i in range(4):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, 1, n], \n",
    "                     [1, n, n, 1],\n",
    "                     [1, n, n, 1],\n",
    "                     [n, 1, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states() ## if has recurrent layers\n",
    "for i in range(2):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(tf.constant([[0, 100]]))) ## should be ~ 101\n",
    "print(model(tf.constant([[0, 10]]))) ## should be ~ 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced graph data\n",
    "In this case, we suppose to have a collective state that will evolve accordingly the node execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "feature_state = tf.constant([[1],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
    "output_state = tf.constant([[0],[n],[n],[n],[1],[2],[3],[4]], dtype=tf.float32)\n",
    "state = tf.constant([[0],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
    "#state = tf.random.uniform((8, 1), minval=0, maxval=1)\n",
    "\n",
    "input_state = tf.concat([feature_state, output_state, state], axis = 1)\n",
    "input_state = input_state[:,tf.newaxis, :]\n",
    "\n",
    "neigh_state = tf.constant([\n",
    "                     [n, 1, n, n, n, n, n, n],\n",
    "                     [1, n, 1, n, n, n, n, n],\n",
    "                     [n, 1, n, 1, n, n, n, n],\n",
    "                     [n, n, 1, n, n, n, n, n],\n",
    "                     [n, n, n, n, n, 1, n, n],\n",
    "                     [n, n, n, n, 1, n, 1, n],\n",
    "                     [n, n, n, n, n, 1, n, 1],\n",
    "                     [n, n, n, n, n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "ground_state = tf.constant([[0],[1],[2],[3],[n],[n],[n],[n]], dtype=tf.float32)\n",
    "## normalisation\n",
    "feature_state = feature_state / n\n",
    "output_state = output_state / n\n",
    "neigh_state = neigh_state / n\n",
    "ground_state = ground_state / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass rivisited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_state(result, neigh, feature, model_eval, log_enable=False):\n",
    "  input_shape_data = result[:, :, 1:]\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  old_output = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  old_state = tf.reshape(result[:,:,2], feature.shape[0])\n",
    "  max_value = tf.reduce_max(neigh)\n",
    "  neigh_with_zero = tf.where(neigh == max_value, 0.0, 1.0)\n",
    "  neigh_output_evaluation = tf.reduce_min(tf.multiply(neigh, old_output), 1) ## pass reduction strategy\n",
    "  neigh_state_evaluation = tf.reduce_sum(tf.multiply(neigh_with_zero, old_state), 1) ## state evolution strategy\n",
    "  neigh_count = tf.reduce_sum(neigh_with_zero, 1)\n",
    "  neigh_state_evaluation = neigh_state_evaluation / neigh_count # mean\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_output_evaluation[:, tf.newaxis], neigh_state_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model_eval(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, (input_shape_data.shape[0], input_shape_data.shape[2])) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss =  3.7822096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-222c9244f23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_with_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-620ccdc30a78>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each, verbose, store)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meach\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MinGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MinGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_MinOrMaxGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MinOrMaxGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    236\u001b[0m       math_ops.reduce_sum(indicators, op.inputs[1]), output_shape_kept_dims)\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_selected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mdivide\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    467\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m   \"\"\"\n\u001b[0;32m-> 1336\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"truediv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0mx_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"convert_to_tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m def convert_to_tensor(value,\n\u001b[1;32m   1483\u001b[0m                       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "model_state = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
    "#model_state = tf.keras.models.load_model('epoch/best_fit_2')\n",
    "iteration = 500\n",
    "stabilise_in = 10\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data_state = (input_state, neigh_state, feature_state, ground_state)\n",
    "train(model_state, forward_with_state, data_state, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)\n",
    "model_state.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  1.        79.393036 113.86746 ]]\n",
      "\n",
      " [[  0.        79.42354  113.833855]]\n",
      "\n",
      " [[  0.        79.425606 113.83249 ]]\n",
      "\n",
      " [[  0.        79.42569  113.83243 ]]\n",
      "\n",
      " [[  0.        79.4257   113.83243 ]]\n",
      "\n",
      " [[  0.        79.4257   113.83243 ]]\n",
      "\n",
      " [[  0.        79.4257   113.83243 ]]\n",
      "\n",
      " [[  0.        79.4257   113.83243 ]]], shape=(8, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  0.]\n",
      " [  1.]\n",
      " [  2.]\n",
      " [  3.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]], shape=(8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = input_state\n",
    "for i in range(10):\n",
    "  result = forward_with_state(result, neigh_state, feature_state, model_state, False)\n",
    "print(result * n)\n",
    "print(ground_state * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation using GA\n",
    "Another way to solve this problem could be leveraging Genetic Algorithm in order to fit the behaviour.\n",
    "In this casa I used [PyGAD](https://arxiv.org/pdf/2106.06158.pdf#page=6&zoom=100,196,781).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import pygad.kerasga\n",
    "import numpy\n",
    "import math\n",
    "import pygad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0  \n",
    "def callback_generation_factory(each = 5):\n",
    "  count = 0\n",
    "  def callback_generation(ga_instance):\n",
    "    global count\n",
    "    if(count % each == 0):\n",
    "      print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "      print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
    "    count += 1\n",
    "  return callback_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, input, neigh, feature, ground, forward_fn, stabilise_in, stabilisation_check):\n",
    "  result = input_state\n",
    "  loss = tensorflow.keras.losses.mse\n",
    "  to_backprop = 0\n",
    "  for i in range(stabilise_in):\n",
    "    result = forward_fn(result, neigh_state, feature_state, model)\n",
    "  for i in range(stabilisation_check):\n",
    "    result = forward_fn(result, neigh_state, feature_state, model)\n",
    "    to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
    "  return to_backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_factory(model, forward_fn, data, stabilise_in, stabilisation_check):\n",
    "  input, neigh, feature, ground = data\n",
    "  \n",
    "  def fitness(solution, sol_idx):\n",
    "    global keras_ga\n",
    "    solution_weights = pygad.kerasga.model_weights_as_matrix(model=model, weights_vector=solution)\n",
    "    model.set_weights(solution_weights)\n",
    "    error = eval_model(model, input, neigh, feature, ground, forward_fn, stabilise_in, stabilisation_check)\n",
    "    mse_error = tf.reduce_sum(error).numpy() + 0.00000001\n",
    "    solution_fitness = 1.0/mse_error\n",
    "    solution_fitness = 0 if math.isnan(solution_fitness) else solution_fitness\n",
    "    return solution_fitness\n",
    "  return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Generation = 36\n",
      "Fitness    = 127.00324910174302\n",
      "Generation = 86\n",
      "Fitness    = 127.00324910174302\n",
      "Generation = 136\n",
      "Fitness    = 127.00324910174302\n",
      "Generation = 186\n",
      "Fitness    = 127.00324910174302\n",
      "Generation = 236\n",
      "Fitness    = 127.00324910174302\n",
      "Generation = 286\n",
      "Fitness    = 127.23853925026391\n",
      "Generation = 336\n",
      "Fitness    = 127.23853925026391\n",
      "Generation = 386\n",
      "Fitness    = 127.24236912233862\n",
      "Generation = 436\n",
      "Fitness    = 127.28852665256973\n",
      "Generation = 486\n",
      "Fitness    = 127.28852665256973\n",
      "Generation = 536\n",
      "Fitness    = 127.28852665256973\n",
      "Generation = 586\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 636\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 686\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 736\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 786\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 836\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 886\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 936\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 986\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 1036\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 1086\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 1136\n",
      "Fitness    = 127.33598614432928\n",
      "Generation = 1186\n",
      "Fitness    = 129.12273473927863\n",
      "Generation = 1236\n",
      "Fitness    = 129.12273473927863\n",
      "Generation = 1286\n",
      "Fitness    = 129.12273473927863\n",
      "Generation = 1336\n",
      "Fitness    = 129.12273473927863\n",
      "Generation = 1386\n",
      "Fitness    = 129.80476768631198\n",
      "Generation = 1436\n",
      "Fitness    = 129.80476768631198\n",
      "Generation = 1486\n",
      "Fitness    = 129.80476768631198\n",
      "Generation = 1536\n",
      "Fitness    = 129.80476768631198\n",
      "Generation = 1586\n",
      "Fitness    = 129.80476768631198\n",
      "Generation = 1636\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1686\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1736\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1786\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1836\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1886\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1936\n",
      "Fitness    = 129.85936781122584\n",
      "Generation = 1986\n",
      "Fitness    = 130.86552995461886\n",
      "Generation = 2036\n",
      "Fitness    = 131.19817354265336\n",
      "Generation = 2086\n",
      "Fitness    = 131.43115363783977\n",
      "Generation = 2136\n",
      "Fitness    = 131.43115363783977\n",
      "Generation = 2186\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2236\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2286\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2336\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2386\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2436\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2486\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2536\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2586\n",
      "Fitness    = 133.4912977687085\n",
      "Generation = 2636\n",
      "Fitness    = 133.53692774118866\n",
      "Generation = 2686\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2736\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2786\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2836\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2886\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2936\n",
      "Fitness    = 133.537500700589\n",
      "Generation = 2986\n",
      "Fitness    = 133.83473919260692\n",
      "Generation = 3036\n",
      "Fitness    = 135.9094483303285\n",
      "Generation = 3086\n",
      "Fitness    = 135.9094483303285\n",
      "Generation = 3136\n",
      "Fitness    = 135.9094483303285\n",
      "Generation = 3186\n",
      "Fitness    = 136.16744604558974\n",
      "Generation = 3236\n",
      "Fitness    = 136.64353962328107\n",
      "Generation = 3286\n",
      "Fitness    = 139.4597726609357\n",
      "Generation = 3336\n",
      "Fitness    = 139.4597726609357\n",
      "Generation = 3386\n",
      "Fitness    = 139.75680123869222\n",
      "Generation = 3436\n",
      "Fitness    = 140.23773540022637\n",
      "Generation = 3486\n",
      "Fitness    = 140.23773540022637\n",
      "Generation = 3536\n",
      "Fitness    = 140.37362491432776\n",
      "Generation = 3586\n",
      "Fitness    = 140.55478568058524\n",
      "Generation = 3636\n",
      "Fitness    = 140.57041726803365\n",
      "Generation = 3686\n",
      "Fitness    = 140.57041726803365\n",
      "Generation = 3736\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 3786\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 3836\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 3886\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 3936\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 3986\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 4036\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 4086\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 4136\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 4186\n",
      "Fitness    = 140.57402434337357\n",
      "Generation = 4236\n",
      "Fitness    = 141.75545493282976\n",
      "Generation = 4286\n",
      "Fitness    = 142.4159419784538\n",
      "Generation = 4336\n",
      "Fitness    = 142.92150019910386\n",
      "Generation = 4386\n",
      "Fitness    = 142.92150019910386\n",
      "Generation = 4436\n",
      "Fitness    = 142.92150019910386\n",
      "Generation = 4486\n",
      "Fitness    = 142.92150019910386\n",
      "Generation = 4536\n",
      "Fitness    = 143.19188112210958\n",
      "Generation = 4586\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4636\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4686\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4736\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4786\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4836\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4886\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4936\n",
      "Fitness    = 714.2030172760661\n",
      "Generation = 4986\n",
      "Fitness    = 714.2030172760661\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
    "model = tf.keras.models.load_model('model_dense_GA_3')\n",
    "\n",
    "keras_ga = pygad.kerasga.KerasGA(model=model, num_solutions=20)\n",
    "# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
    "num_generations = 5000 # Number of generations.\n",
    "num_parents_mating = 3 # Number of solutions to be selected as parents in the mating pool.\n",
    "stabilise_in = 4\n",
    "stabilisation_check = 7\n",
    "\n",
    "initial_population = keras_ga.population_weights # Initial population of network weights\n",
    "data = (input_state, neigh_state, feature_state, ground_state)\n",
    "fitness_function = fitness_factory(model, forward_with_state, data, stabilise_in, stabilisation_check)\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       keep_parents=2,\n",
    "                       random_mutation_min_val=-2,\n",
    "                       init_range_low=-50,\n",
    "                       init_range_high=50,\n",
    "                       random_mutation_max_val=2,\n",
    "                       mutation_probability=0.01,\n",
    "                       parent_selection_type=\"rws\",\n",
    "                       crossover_probability=0.001,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       initial_population=initial_population,\n",
    "                       fitness_func=fitness_function,\n",
    "                       on_generation=callback_generation_factory(50))\n",
    "\n",
    "ga_instance.run()\n",
    "\n",
    "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
    "ga_instance.plot_fitness(title=\"PyGAD & Keras - Iteration vs. Fitness\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness value of the best solution = 714.2030172760661\n",
      "Index of the best solution : 0\n",
      "tf.Tensor(\n",
      "[[[1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 5.0941778e+05 4.2869570e+06]]\n",
      "\n",
      " [[0.0000000e+00 6.7734775e+05 3.9913952e+06]]\n",
      "\n",
      " [[0.0000000e+00 6.5917795e+06 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 6.5917795e+06 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 6.5917795e+06 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 6.5917795e+06 0.0000000e+00]]\n",
      "\n",
      " [[0.0000000e+00 6.5917795e+06 0.0000000e+00]]], shape=(8, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  0.]\n",
      " [  1.]\n",
      " [  2.]\n",
      " [  3.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]], shape=(8, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "714.2030172760661"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returning the details of the best solution.\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
    "solution_weights = pygad.kerasga.model_weights_as_matrix(model=model, weights_vector=solution)\n",
    "model.set_weights(solution_weights)\n",
    "result = input_state\n",
    "for i in range(stabilise_in):\n",
    "  result = forward_with_state(result, neigh_state, feature_state, model, False)\n",
    "print(result * n)\n",
    "print(ground_state * n)\n",
    "fitness_function(pygad.kerasga.model_weights_as_vector(model), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_dense_GA_4/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_dense_GA_4')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9O5CIu3uDdkZ/uIe7V0gL",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "test-with-rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
