{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test-with-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/test_with_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji2Yp08lPMHJ"
      },
      "source": [
        "# Neural Networks applied in Aggregate Computing\n",
        "In this notebook, I tried to apply Neural Network and Recurrent Neural Networks (RNN) in the context of Aggregate Computing (AC).\n",
        "\n",
        "## Model\n",
        "\n",
        "Usually, RNN are trained in indipendent sequences. In case of Aggregate Computing, the temporal sequence are correlated with each other following a neighbourhood policy. \n",
        "\n",
        "The key idea here is:\n",
        "- express the system as a graph. Offline we can imagine to access to the entire system\n",
        "- in each time step, we aggregate data from the neighbours and then we use RNN to compute the right output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tihJbe7wP_L7"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4IkeCHdg9f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from numpy.random import seed\n",
        "import datetime\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXGw5707Rv7"
      },
      "source": [
        "# Simple Graph\n",
        "\n",
        "In this model, I model graph as:\n",
        "$G = (N, E)$\n",
        "\n",
        "Where, $N$ contains a feature vector and an output vector.\n",
        "\n",
        "$E$ is expressed as adjacency matrix, so: $E_{i,j} = 1$ iff $i$ is neighbour of $j$.\n",
        "\n",
        "Input is a matrix contains the concatenation of feature vector and output vector, something like: $ I(n) = <f(n), o(n)>$.\n",
        "Where $<a, b, c>$ means the column-wise fector concatenation. \n",
        "For instance, giving a vector $a = [1, 2]$ and $b = [2, 3]$, $<a,b> = [1, 2, 2, 3]$.\n",
        "\n",
        "The neighbour aggregation data can be computed leveraging matrix multiplication --- so increasing traning performance.\n",
        "$$ reduction(E * F) $$\n",
        "Where F contains all node features.\n",
        "$reduction$ is a multiset function (e.g. summation, mean,...).\n",
        "\n",
        "Pay attention, this model can be easly used in a decentralized situation.\n",
        "Indeed, the data aggregation will be done without global adjency matrix but only retrieving neighbour data. The dense layer already works locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaicADIO7U34"
      },
      "source": [
        "n = 50000\n",
        "feature = tf.constant([\n",
        "                     [1], \n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0],\n",
        "                    ], dtype=tf.float32)\n",
        "output = tf.constant([\n",
        "                     [0], \n",
        "                     [n],\n",
        "                     [n],\n",
        "                     [n],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "input = tf.concat([feature, output], axis = 1)\n",
        "input = input[:,tf.newaxis, :]\n",
        "\n",
        "neigh = tf.constant([\n",
        "                     [n, 1, n, n], \n",
        "                     [1, n, 1, n],\n",
        "                     [n, 1, n, 1],\n",
        "                     [n, n, 1, n],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "ground = tf.constant([\n",
        "                     [0], \n",
        "                     [1],\n",
        "                     [2],\n",
        "                     [3],\n",
        "                    ], dtype=tf.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRY-rUZ27Y0E"
      },
      "source": [
        "# Forward Pass\n",
        "\n",
        "Taking the output of previous step, adjecency matrix, and feature vector, this function compute the value of the next evaluation.\n",
        "So\n",
        "1. compute neighbourhood feature via aggregation\n",
        "2. concat neighbourhood feature with local feature and previous output\n",
        "3. perform a forward pass of a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKorlgUN7arq"
      },
      "source": [
        "def forward(result, neigh, feature, model, log_enable=False):\n",
        "  if(log_enable):\n",
        "    print(\"Input = \", result)\n",
        "  reshape = tf.reshape(result[:,:, 1], feature.shape[0])\n",
        "  neigh_evaluation = tf.reduce_min(tf.multiply(neigh, reshape), 1) ## pass reduction strategy\n",
        "  input_network = tf.concat([result[:,:, 0], neigh_evaluation[:, tf.newaxis]], 1)\n",
        "  if(log_enable):\n",
        "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
        "  result = model(input_network[:, tf.newaxis])\n",
        "  result = tf.reshape(result, feature.shape[:2]) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
        "  result = tf.concat([feature, result], axis = 1)\n",
        "  if(log_enable):\n",
        "    print(\"Output = \", result)\n",
        "  return tf.expand_dims(result, [1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aJqP660S5W4"
      },
      "source": [
        "# Model creation\n",
        "Create a sequential model given layers and the input shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdXR3Tb3TV8l"
      },
      "source": [
        "def create_model(input_shape, layers):\n",
        "  input_layer = tf.keras.layers.InputLayer(input_shape=input_shape[1:], batch_size=input_shape[0])\n",
        "  layers.insert(0, input_layer)\n",
        "  return tf.keras.Sequential(layers)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibOdTAPsnGEf"
      },
      "source": [
        "## Recurrent model\n",
        "Simple network creation with multiple recurrent layer \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oNvEE-Bh4B1"
      },
      "source": [
        "def instantiate_layers(output_count = 1):\n",
        "  return [\n",
        "    tf.keras.layers.GRU(units = 4, activation='relu', return_sequences=True, stateful=True),\n",
        "    tf.keras.layers.GRU(units = output_count, activation='relu', return_sequences=False, stateful=True, bias_initializer='ones'),\n",
        "  ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLAigDrToouO"
      },
      "source": [
        "## Linear Model\n",
        "Simple network with multiple linear layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DneyuoJoltR"
      },
      "source": [
        "def instantiate_linear_layers(output_count = 1):\n",
        "  return [\n",
        "    tf.keras.layers.Dense(units = 32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units = 16, activation='relu'),\n",
        "    tf.keras.layers.Dense(units = 8, activation='relu'),\n",
        "    tf.keras.layers.Dense(units = 4, activation='relu'),\n",
        "    tf.keras.layers.Dense(units = output_count, activation='relu', kernel_initializer='lecun_normal',bias_initializer='ones')\n",
        "  ]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2iXarjQrq10"
      },
      "source": [
        "## Model instatiation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFidlC53rvyL"
      },
      "source": [
        "linear = \"linear\"\n",
        "recurrent = \"recurrent\"\n",
        "same = \"same\"\n",
        "\n",
        "def instatiate(input, mode = \"same\", output_count = 1):\n",
        "  if mode == linear:\n",
        "    return create_model(input.shape, instantiate_linear_layers(output_count))\n",
        "  elif mode == recurrent:\n",
        "    return create_model(input.shape, instantiate_layers(output_count))\n",
        "\n",
        "def copy_model(model, mode = \"same\", input = \"\", output_count = 1):\n",
        "  if mode == linear:\n",
        "    return model\n",
        "  elif mode == recurrent:\n",
        "    change_model = instatiate(input, recurrent, output_count)\n",
        "    change_model.set_weights(model.get_weights())\n",
        "    return change_model\n",
        "mode = linear\n",
        "model = instatiate(input, linear)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZquNuutUD-n"
      },
      "source": [
        "# Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvzeO1W3UGi4"
      },
      "source": [
        "## TODO pass input and network\n",
        "def train(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each=100, verbose=False, store=False):\n",
        "  input, neigh, feature, ground = data\n",
        "  for j in range(iteration):\n",
        "    with tf.GradientTape() as tape:\n",
        "      result = input\n",
        "      to_backprop = 0\n",
        "      for i in range(stabilise_in):\n",
        "        result = forward_fn(result, neigh, feature, model)\n",
        "      for i in range(stabilisation_check):\n",
        "        result = forward_fn(result, neigh, feature, model)\n",
        "        to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
        "      model.reset_states()\n",
        "      \n",
        "      gradient = tape.gradient(to_backprop, model.weights)\n",
        "      optimizer.apply_gradients(zip(gradient, model.weights))\n",
        "    if(j % each == 0):\n",
        "      if(verbose == True):\n",
        "        partial_result = result[:, 0, 1:2]\n",
        "        tf.print(\"Ground truth: \\n\", tf.reshape(ground, ground.shape[0]))\n",
        "        tf.print(\"Current prediciton \\n\", tf.reshape(partial_result, result.shape[0]))\n",
        "        tf.print(\"Full output \\n\", result)\n",
        "      if(store):\n",
        "        model.save('epoch/model_dense_' + str(j))\n",
        "      print(\"Epoch \", j ,\"Loss = \", tf.reduce_sum(to_backprop).numpy())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFGPPgD_hdHi"
      },
      "source": [
        "\n",
        "## Train loop\n",
        "Here I want only to find a function that overfits, so it solve this specific problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "56wyzp3MdzYy",
        "outputId": "263ff0df-8166-4350-967a-cda428d79db5"
      },
      "source": [
        "#seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "model = instatiate(input, mode) ## comment to avoid the recomputation of weights\n",
        "\n",
        "iteration = 2000\n",
        "stabilise_in = 2\n",
        "stabilisation_check = 10\n",
        "\n",
        "loss = tf.losses.mse\n",
        "optimizer = tf.optimizers.Adam()\n",
        "data = (input, neigh, feature, ground)\n",
        "train(model, forward, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 Loss =  6.0242467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-29231d3cf1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-620ccdc30a78>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each, verbose, store)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meach\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/types.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, ownerclass)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unreadable attribute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/enum.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mDynamicClassAttribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;34m\"\"\"The value of the Enum member.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfW4VKUuux9c"
      },
      "source": [
        "# Validation\n",
        "Check the model result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw1oCt67ux9c",
        "outputId": "4eb11f44-7158-4d38-cfab-ffbf7aa76c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = input\n",
        "for i in range(10):\n",
        "  result = forward(result, neigh, feature, model)\n",
        "print(result)\n",
        "model.reset_states()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[1.        1.010453 ]]\n",
            "\n",
            " [[0.        1.0544702]]\n",
            "\n",
            " [[0.        1.0544617]]\n",
            "\n",
            " [[0.        1.0544617]]], shape=(4, 1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "warD1kFTux9c"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLlFmSiGux9c"
      },
      "source": [
        "model.save('model_dense_2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqbsEJEnWOc7"
      },
      "source": [
        "# Check result, generalisation\n",
        "In this part, I try to use the same network in another graph, to see if it can be used in different graphs.\n",
        "\n",
        "## Linear network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LDTXF5knmGv"
      },
      "source": [
        "n = 50000\n",
        "feature_validation = tf.constant([\n",
        "                     [1], \n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0]\n",
        "                    ], dtype=tf.float32)\n",
        "output_validation = tf.constant([\n",
        "                     [0], \n",
        "                     [n],\n",
        "                     [n],\n",
        "                     [n],\n",
        "                     [n]\n",
        "                    ], dtype=tf.float32)\n",
        "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
        "input_validation = input_validation[:,tf.newaxis, :]\n",
        "neigh_validation = tf.constant([\n",
        "                     [n, 1, n, n, n], \n",
        "                     [1, n, 1, n, n],\n",
        "                     [n, 1, n, 1, n],\n",
        "                     [n, n, 1, n, 1],\n",
        "                     [n, n, n, 1, n],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "change_model = copy_model(model, mode, input_validation)\n",
        "\n",
        "result_validation = input_validation\n",
        "model.reset_states()\n",
        "for i in range(4):\n",
        "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
        "print(result_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U7vKLDLux9d"
      },
      "source": [
        "## Square like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0i3JozYux9d"
      },
      "source": [
        "n = 50000\n",
        "feature_validation = tf.constant([\n",
        "                     [1], \n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0],\n",
        "                    ], dtype=tf.float32)\n",
        "output_validation = tf.constant([\n",
        "                     [0], \n",
        "                     [n],\n",
        "                     [n],\n",
        "                     [n],\n",
        "                    ], dtype=tf.float32)\n",
        "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
        "input_validation = input_validation[:,tf.newaxis, :]\n",
        "neigh_validation = tf.constant([\n",
        "                     [n, 1, 1, n], \n",
        "                     [1, n, n, 1],\n",
        "                     [1, n, n, 1],\n",
        "                     [n, 1, 1, n],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "change_model = copy_model(model, mode, input_validation)\n",
        "\n",
        "result_validation = input_validation\n",
        "model.reset_states() ## if has recurrent layers\n",
        "for i in range(2):\n",
        "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
        "print(result_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF6xoMl5ux9e"
      },
      "source": [
        "## Local test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5haxek8ux9e"
      },
      "source": [
        "print(model(tf.constant([[0, 100]]))) ## should be ~ 101\n",
        "print(model(tf.constant([[0, 10]]))) ## should be ~ 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHVrOZFxux9e"
      },
      "source": [
        "# Advanced graph data\n",
        "In this case, we suppose to have a collective state that will evolve accordingly the node execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtqsIucqux9f"
      },
      "source": [
        "n = 100\n",
        "feature_state = tf.constant([[1],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
        "output_state = tf.constant([[0],[n],[n],[n],[1],[2],[3],[4]], dtype=tf.float32)\n",
        "state = tf.constant([[0],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
        "#state = tf.random.uniform((8, 1), minval=0, maxval=1)\n",
        "\n",
        "input_state = tf.concat([feature_state, output_state, state], axis = 1)\n",
        "input_state = input_state[:,tf.newaxis, :]\n",
        "\n",
        "neigh_state = tf.constant([\n",
        "                     [n, 1, n, n, n, n, n, n],\n",
        "                     [1, n, 1, n, n, n, n, n],\n",
        "                     [n, 1, n, 1, n, n, n, n],\n",
        "                     [n, n, 1, n, n, n, n, n],\n",
        "                     [n, n, n, n, n, 1, n, n],\n",
        "                     [n, n, n, n, 1, n, 1, n],\n",
        "                     [n, n, n, n, n, 1, n, 1],\n",
        "                     [n, n, n, n, n, n, 1, n],\n",
        "                    ], dtype=tf.float32)\n",
        "ground_state = tf.constant([[0],[1],[2],[3],[n],[n],[n],[n]], dtype=tf.float32)\n",
        "## normalisation\n",
        "feature_state = feature_state / n\n",
        "output_state = output_state / n\n",
        "neigh_state = neigh_state / n\n",
        "ground_state = ground_state / n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BseoZcAYux9f"
      },
      "source": [
        "## Forward pass rivisited\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wn7P4zhux9f"
      },
      "source": [
        "def forward_with_state(result, neigh, feature, model_eval, log_enable=False):\n",
        "  input_shape_data = result[:, :, 1:]\n",
        "  if(log_enable):\n",
        "    print(\"Input = \", result)\n",
        "  old_output = tf.reshape(result[:,:, 1], feature.shape[0])\n",
        "  old_state = tf.reshape(result[:,:,2], feature.shape[0])\n",
        "  max_value = tf.reduce_max(neigh)\n",
        "  neigh_with_zero = tf.where(neigh == max_value, 0.0, 1.0)\n",
        "  neigh_output_evaluation = tf.reduce_min(tf.multiply(neigh, old_output), 1) ## pass reduction strategy\n",
        "  neigh_state_evaluation = tf.reduce_sum(tf.multiply(neigh_with_zero, old_state), 1) ## state evolution strategy\n",
        "  neigh_count = tf.reduce_sum(neigh_with_zero, 1)\n",
        "  neigh_state_evaluation = neigh_state_evaluation / neigh_count # mean\n",
        "  input_network = tf.concat([result[:,:, 0], neigh_output_evaluation[:, tf.newaxis], neigh_state_evaluation[:, tf.newaxis]], 1)\n",
        "  if(log_enable):\n",
        "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
        "  result = model_eval(input_network[:, tf.newaxis])\n",
        "  result = tf.reshape(result, (input_shape_data.shape[0], input_shape_data.shape[2])) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
        "  result = tf.concat([feature, result], axis = 1)\n",
        "  if(log_enable):\n",
        "    print(\"Output = \", result)\n",
        "  return tf.expand_dims(result, [1])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMS-g8tVux9g"
      },
      "source": [
        "# Train revisited"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emn-8aeiux9g",
        "outputId": "4494f399-e777-4d2c-db6b-9970254eaf2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "model_state = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
        "#model_state = tf.keras.models.load_model('epoch/best_fit_2')\n",
        "iteration = 500\n",
        "stabilise_in = 10\n",
        "stabilisation_check = 10\n",
        "\n",
        "loss = tf.losses.mse\n",
        "optimizer = tf.optimizers.Adam()\n",
        "data_state = (input_state, neigh_state, feature_state, ground_state)\n",
        "train(model_state, forward_with_state, data_state, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)\n",
        "model_state.reset_states()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 Loss =  3.8462243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-222c9244f23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_with_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-620ccdc30a78>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each, verbose, store)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mto_backprop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstabilisation_check\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b9a079e961bf>\u001b[0m in \u001b[0;36mforward_with_state\u001b[0;34m(result, neigh, feature, model_eval, log_enable)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neighbour Aggregation = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## adapt the shape in order to work both in linear model and in the recurrent model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36minput_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_spec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# `Trackable` manages the `_layers` attributes and does filtering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# over it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2487\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2821\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2822\u001b[0m     for m in self._flatten_modules(\n\u001b[0;32m-> 2823\u001b[0;31m         recursive=recursive, include_self=include_self):\n\u001b[0m\u001b[1;32m   2824\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_modules\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2845\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mtrackable_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m         \u001b[0mtrackable_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrackable_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_object_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m           \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqSvfzKux9h"
      },
      "source": [
        "# Validation revisited"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhxUrXhgux9h",
        "outputId": "b2e4b761-cfe5-410a-a587-9ddba8f9628f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result = input_state\n",
        "for i in range(10):\n",
        "  result = forward_with_state(result, neigh_state, feature_state, model_state, False)\n",
        "print(result * n)\n",
        "print(ground_state * n)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[  1.        84.336105 116.868904]]\n",
            "\n",
            " [[  0.        84.33935  116.86791 ]]\n",
            "\n",
            " [[  0.        84.33938  116.867874]]\n",
            "\n",
            " [[  0.        84.33938  116.867874]]\n",
            "\n",
            " [[  0.        84.33938  116.867874]]\n",
            "\n",
            " [[  0.        84.33938  116.867874]]\n",
            "\n",
            " [[  0.        84.339386 116.867874]]\n",
            "\n",
            " [[  0.        84.339386 116.867874]]], shape=(8, 1, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[  0.]\n",
            " [  1.]\n",
            " [  2.]\n",
            " [  3.]\n",
            " [100.]\n",
            " [100.]\n",
            " [100.]\n",
            " [100.]], shape=(8, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm6t8idxux9i"
      },
      "source": [
        "# Model evaluation using GA\n",
        "Another way to solve this problem could be leveraging Genetic Algorithm in order to fit the behaviour.\n",
        "In this casa I used [PyGAD](https://arxiv.org/pdf/2106.06158.pdf#page=6&zoom=100,196,781).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KECVOokrvQW8"
      },
      "source": [
        "## Installation of PyGad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_MnrhTuvTGK",
        "outputId": "3e596c29-919e-4bad-f981-679a31c56417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install pygad"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygad\n",
            "  Downloading pygad-2.16.0-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzVVqaPLux9i"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Hc3Bgtux9i"
      },
      "source": [
        "import tensorflow.keras\n",
        "import pygad.kerasga\n",
        "import numpy\n",
        "import math\n",
        "import pygad"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cPfC5SNux9i"
      },
      "source": [
        "## Callback after each iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsUHiOl_ux9i"
      },
      "source": [
        "count = 0  \n",
        "def callback_generation_factory(each = 5):\n",
        "  count = 0\n",
        "  def callback_generation(ga_instance):\n",
        "    global count\n",
        "    if(count % each == 0):\n",
        "      print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "      print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    count += 1\n",
        "  return callback_generation"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHfbR8iGux9j"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSSl3svcux9j"
      },
      "source": [
        "def eval_model(model, input, neigh, feature, ground, forward_fn, stabilise_in, stabilisation_check):\n",
        "  result = input_state\n",
        "  loss = tensorflow.keras.losses.mse\n",
        "  to_backprop = 0\n",
        "  for i in range(stabilise_in):\n",
        "    result = forward_fn(result, neigh_state, feature_state, model)\n",
        "  for i in range(stabilisation_check):\n",
        "    result = forward_fn(result, neigh_state, feature_state, model)\n",
        "    to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
        "  return (result, to_backprop)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEVzjibyux9j"
      },
      "source": [
        "## Fitness function factory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_a7SUMPux9j"
      },
      "source": [
        "def fitness_factory(model, forward_fn, data, stabilise_in, stabilisation_check):\n",
        "  input, neigh, feature, ground = data\n",
        "  \n",
        "  def fitness(solution, sol_idx):\n",
        "    global keras_ga\n",
        "    solution_weights = pygad.kerasga.model_weights_as_matrix(model=model, weights_vector=solution)\n",
        "    model.set_weights(solution_weights)\n",
        "    _, error = eval_model(model, input, neigh, feature, ground, forward_fn, stabilise_in, stabilisation_check)\n",
        "    mse_error = tf.reduce_sum(error).numpy()\n",
        "    solution_fitness = 1.0/mse_error\n",
        "    solution_fitness = 0 if math.isnan(solution_fitness) else solution_fitness\n",
        "    return solution_fitness\n",
        "  return fitness"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWp8S_Lyux9k"
      },
      "source": [
        "## GA run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "RKIdCVPxux9k",
        "outputId": "fab9f207-43f2-45ad-9c4a-ffa6d36fbab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
        "#model = tf.keras.models.load_model('model_dense_GA_3')\n",
        "\n",
        "keras_ga = pygad.kerasga.KerasGA(model=model, num_solutions=20)\n",
        "# Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
        "num_generations = 5000 # Number of generations.\n",
        "num_parents_mating = 3 # Number of solutions to be selected as parents in the mating pool.\n",
        "stabilise_in = 4\n",
        "stabilisation_check = 7\n",
        "\n",
        "initial_population = keras_ga.population_weights # Initial population of network weights\n",
        "data = (input_state, neigh_state, feature_state, ground_state)\n",
        "fitness_function = fitness_factory(model, forward_with_state, data, stabilise_in, stabilisation_check)\n",
        "\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       keep_parents=2,\n",
        "                       random_mutation_min_val=-2,\n",
        "                       init_range_low=-50,\n",
        "                       init_range_high=50,\n",
        "                       random_mutation_max_val=2,\n",
        "                       mutation_probability=0.01,\n",
        "                       parent_selection_type=\"rws\",\n",
        "                       crossover_probability=0.001,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       initial_population=initial_population,\n",
        "                       fitness_func=fitness_function,\n",
        "                       on_generation=callback_generation_factory(50))\n",
        "\n",
        "ga_instance.run()\n",
        "\n",
        "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
        "ga_instance.plot_fitness(title=\"PyGAD & Keras - Iteration vs. Fitness\", linewidth=4)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation = 48\n",
            "Fitness    = 0.7855133666649781\n",
            "Generation = 98\n",
            "Fitness    = 40.82417688707797\n",
            "Generation = 148\n",
            "Fitness    = 713.4974809775472\n",
            "Generation = 198\n",
            "Fitness    = 713.4974809775472\n",
            "Generation = 248\n",
            "Fitness    = 714.2638828511836\n",
            "Generation = 298\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 348\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 398\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 448\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 498\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 548\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 598\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 648\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 698\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 748\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 798\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 848\n",
            "Fitness    = 714.285680358965\n",
            "Generation = 898\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 948\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 998\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1048\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1098\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1148\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1198\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1248\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1298\n",
            "Fitness    = 714.2857397545366\n",
            "Generation = 1348\n",
            "Fitness    = 714.2857397545366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b22c26eef98d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                        on_generation=callback_generation_factory(50))\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;31m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_pop_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mbest_solution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_solution_fitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_match_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_fitness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mcal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;31m# Calculating the fitness value of each solution in the current population.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m             \u001b[0mpop_fitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-5ac980f4bc65>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(solution, sol_idx)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msolution_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkerasga\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_weights_as_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmse_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msolution_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmse_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-dbe8062d32ee>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, input, neigh, feature, ground, forward_fn, stabilise_in, stabilisation_check)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mto_backprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilise_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-b9a079e961bf>\u001b[0m in \u001b[0;36mforward_with_state\u001b[0;34m(result, neigh, feature, model_eval, log_enable)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neighbour Aggregation = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_shape_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## adapt the shape in order to work both in linear model and in the recurrent model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mTensor\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[1;32m   4733\u001b[0m     \u001b[0mclip_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4734\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4735\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4737\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(features, name)\u001b[0m\n\u001b[1;32m  10476\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10477\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m> 10478\u001b[0;31m         _ctx, \"Relu\", name, features)\n\u001b[0m\u001b[1;32m  10479\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10480\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20ov14X6ux9l"
      },
      "source": [
        "## GA evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p67RQAKOux9l",
        "outputId": "2755168d-2dce-4699-a657-7c46f129aa3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Returning the details of the best solution.\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
        "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
        "solution_weights = pygad.kerasga.model_weights_as_matrix(model=model, weights_vector=solution)\n",
        "model.set_weights(solution_weights)\n",
        "result = input_state\n",
        "result, error = eval_model(model, input_state, neigh_state, feature_state, ground_state, forward_with_state, stabilise_in, stabilisation_check)\n",
        "print(\"Fitness function :\", fitness_function(pygad.kerasga.model_weights_as_vector(model), 0))\n",
        "print(\"Loss : \", tf.reduce_sum(error).numpy())\n",
        "print(\"Loss check : \", 1.0 / tf.reduce_sum(error).numpy())\n",
        "print(\"Result \", result)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitness value of the best solution = 714.2857397545366\n",
            "Index of the best solution : 0\n",
            "Fitness function : 714.2857397545366\n",
            "Loss :  0.0014\n",
            "Loss check :  714.2857397545366\n",
            "Result  tf.Tensor(\n",
            "[[[9.9999998e-03 0.0000000e+00 1.5381673e+25]]\n",
            "\n",
            " [[0.0000000e+00 0.0000000e+00 1.8181552e+20]]\n",
            "\n",
            " [[0.0000000e+00 0.0000000e+00 1.5336691e+25]]\n",
            "\n",
            " [[0.0000000e+00 0.0000000e+00 1.8074131e+20]]\n",
            "\n",
            " [[0.0000000e+00 9.9999928e-01 0.0000000e+00]]\n",
            "\n",
            " [[0.0000000e+00 9.9999928e-01 0.0000000e+00]]\n",
            "\n",
            " [[0.0000000e+00 9.9999928e-01 0.0000000e+00]]\n",
            "\n",
            " [[0.0000000e+00 9.9999928e-01 0.0000000e+00]]], shape=(8, 1, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q60apyaEux9l",
        "outputId": "f66e7493-78d9-4211-89ac-64add09635f1"
      },
      "source": [
        "model.save('model_dense_GA_4')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_dense_GA_4/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}