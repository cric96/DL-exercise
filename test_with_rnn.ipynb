{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test-with-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsnharmRdxOceU1nHHProj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/test_with_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji2Yp08lPMHJ"
      },
      "source": [
        "# Recurrent Neural Network applied in Aggregate Computing\n",
        "In this notebook, I tried to apply Recurrent Neural Networks (RNN) in the context of Aggregate Computing (AC).\n",
        "\n",
        "## Model\n",
        "\n",
        "Usually, RNN are trained in indipendent sequences. In case of Aggregate Computing, the temporal sequence are correlated with each other following a neighbourhood policy. \n",
        "\n",
        "The key idea here is:\n",
        "- express the system as a graph. Offline we can imagine to access to the entire system\n",
        "- in each time step, we aggregate data from the neighbours and then we use RNN to compute the right output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tihJbe7wP_L7"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld4IkeCHdg9f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "from datetime import datetime\n",
        "from numpy.random import seed\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXGw5707Rv7"
      },
      "source": [
        "# Simple Graph\n",
        "\n",
        "In this model, I model graph as:\n",
        "$G = (N, E)$\n",
        "\n",
        "Where, $N$ contains a feature vector and an output vector.\n",
        "\n",
        "$E$ is expressed as adjacency matrix, so: $E_{i,j} = 1$ iff $i$ is neighbour of $j$.\n",
        "\n",
        "Input is a matrix contains the concatenation of feature vector and output vector, something like: $ I(n) = <f(n), o(n)>$.\n",
        "Where $<a, b, c>$ means the column-wise fector concatenation. \n",
        "For instance, giving a vector $a = [1, 2]$ and $b = [2, 3]$, $<a,b> = [1, 2, 2, 3]$.\n",
        "\n",
        "The neighbour aggregation data can be computed leveraging matrix multiplication --- so increasing traning performance.\n",
        "$$ reduction(E * F) $$\n",
        "Where F contains all node features.\n",
        "$reduction$ is a multiset function (e.g. summation, mean,...).\n",
        "\n",
        "Pay attention, this model can be easly used in a decentralized situation.\n",
        "Indeed, the data aggregation will be done without global adjency matrix but only retrieving neighbour data. The dense layer already works locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaicADIO7U34"
      },
      "source": [
        "feature = tf.constant([\n",
        "                     [1], \n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0],\n",
        "                    ], dtype=tf.float32)\n",
        "output = tf.constant([\n",
        "                     [100.0], \n",
        "                     [100.0],\n",
        "                     [100.0],\n",
        "                     [100.0],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "input = tf.concat([feature, output], axis = 1)\n",
        "input = input[:,tf.newaxis, :]\n",
        "\n",
        "n = 10000\n",
        "neigh = tf.constant([\n",
        "                     [n, 1, n, n], \n",
        "                     [1, n, 1, n],\n",
        "                     [n, 1, n, 1],\n",
        "                     [n, n, 1, n],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "ground = tf.constant([\n",
        "                     [1, 0], \n",
        "                     [0, 1],\n",
        "                     [0, 2],\n",
        "                     [0, 3],\n",
        "                    ], dtype=tf.float32)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRY-rUZ27Y0E"
      },
      "source": [
        "# Forward Pass\n",
        "\n",
        "Taking the output of previous step, adjecency matrix, and feature vector, this function compute the value of the next evaluation.\n",
        "So\n",
        "1. compute neighbourhood feature via aggregation\n",
        "2. concat neighbourhood feature with local feature and previous output\n",
        "3. perform a forward pass of a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKorlgUN7arq"
      },
      "source": [
        "def forward(result, neigh, feature, eval_logic, log_enable=False):\n",
        "  if(log_enable):\n",
        "    print(\"Input = \", result)\n",
        "  reshape = tf.reshape(result[:,:, 1], feature.shape[0])\n",
        "  neigh_evaluation = tf.reduce_min(tf.multiply(neigh, reshape), 1) ## pass reduction strategy\n",
        "  input_network = tf.concat([result[:,:, 0], neigh_evaluation[:, tf.newaxis]], 1)\n",
        "  if(log_enable):\n",
        "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
        "  result = eval_logic(input_network[:, tf.newaxis])\n",
        "  result = tf.concat([feature, result], axis = 1)\n",
        "  if(log_enable):\n",
        "    print(\"Output = \", result)\n",
        "  return tf.expand_dims(result, [1])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aJqP660S5W4"
      },
      "source": [
        "# Model creation\n",
        "Utilise sequential model to combine rnn with dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdXR3Tb3TV8l"
      },
      "source": [
        "def create_model(input_shape, layers):\n",
        "  input_layer = tf.keras.layers.InputLayer(input_shape=input.shape[1:], batch_size=input_shape[0])\n",
        "  layers.insert(0, input_layer)\n",
        "  return tf.keras.Sequential(layers)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oNvEE-Bh4B1"
      },
      "source": [
        "def instantiate_layers():\n",
        "  return [\n",
        "      tf.keras.layers.GRU(units = 10, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 8, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 8, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 8, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 6, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 6, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 6, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 4, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 4, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 4, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 2, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 2, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 2, activation='selu', return_sequences=True, stateful=True),\n",
        "      tf.keras.layers.GRU(units = 1, activation='selu', return_sequences=False, stateful=True),\n",
        "  ]\n",
        "model = create_model(input.shape, instantiate_layers())"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZquNuutUD-n"
      },
      "source": [
        "# Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvzeO1W3UGi4"
      },
      "source": [
        "## TODO pass input and network\n",
        "def train(model, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each=100):\n",
        "  input, neigh, feature, ground = data\n",
        "  for j in range(iteration):\n",
        "    with tf.GradientTape() as tape:\n",
        "      result = input\n",
        "      to_backprop = 0\n",
        "      for i in range(stabilise_in):\n",
        "        result = forward(result, neigh, feature, model)\n",
        "      for i in range(stabilisation_check):\n",
        "        result = forward(result, neigh, feature, model)\n",
        "        to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, :])\n",
        "      model.reset_states()\n",
        "      gradient = tape.gradient(to_backprop, model.weights)\n",
        "      optimizer.apply_gradients(zip(gradient, model.weights))\n",
        "    if(j % each == 0):\n",
        "      print(\"Epoch \", j ,\"Loss = \", tf.reduce_sum(to_backprop))  "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFGPPgD_hdHi"
      },
      "source": [
        "\n",
        "## RNN With Aggregation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "56wyzp3MdzYy",
        "outputId": "baea858c-eb76-4171-cfbc-0b0c04cc5d8b"
      },
      "source": [
        "#seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "model = create_model(input.shape, instantiate_layers()) ## comment to avoid the recomputation of weights\n",
        "iteration = 1000\n",
        "stabilise_in = 4\n",
        "stabilisation_check = 5\n",
        "\n",
        "loss = tf.losses.mse\n",
        "optimizer = tf.optimizers.Adam()\n",
        "data = (input, neigh, feature, ground)\n",
        "train(model, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, 1)\n",
        "\n",
        "result = input\n",
        "for i in range(20):\n",
        "  result = forward(result, neigh, feature, model, True)\n",
        "print(result)\n",
        "model.reset_states()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 Loss =  tf.Tensor(7.2559156, shape=(), dtype=float32)\n",
            "Epoch  1 Loss =  tf.Tensor(7.1086245, shape=(), dtype=float32)\n",
            "Epoch  2 Loss =  tf.Tensor(6.9480677, shape=(), dtype=float32)\n",
            "Epoch  3 Loss =  tf.Tensor(6.8520117, shape=(), dtype=float32)\n",
            "Epoch  4 Loss =  tf.Tensor(6.774172, shape=(), dtype=float32)\n",
            "Epoch  5 Loss =  tf.Tensor(6.7010155, shape=(), dtype=float32)\n",
            "Epoch  6 Loss =  tf.Tensor(6.631523, shape=(), dtype=float32)\n",
            "Epoch  7 Loss =  tf.Tensor(6.5626, shape=(), dtype=float32)\n",
            "Epoch  8 Loss =  tf.Tensor(6.495734, shape=(), dtype=float32)\n",
            "Epoch  9 Loss =  tf.Tensor(6.4301357, shape=(), dtype=float32)\n",
            "Epoch  10 Loss =  tf.Tensor(6.3663397, shape=(), dtype=float32)\n",
            "Epoch  11 Loss =  tf.Tensor(6.3034215, shape=(), dtype=float32)\n",
            "Epoch  12 Loss =  tf.Tensor(6.240695, shape=(), dtype=float32)\n",
            "Epoch  13 Loss =  tf.Tensor(6.1781483, shape=(), dtype=float32)\n",
            "Epoch  14 Loss =  tf.Tensor(6.114625, shape=(), dtype=float32)\n",
            "Epoch  15 Loss =  tf.Tensor(6.050853, shape=(), dtype=float32)\n",
            "Epoch  16 Loss =  tf.Tensor(5.986686, shape=(), dtype=float32)\n",
            "Epoch  17 Loss =  tf.Tensor(5.921936, shape=(), dtype=float32)\n",
            "Epoch  18 Loss =  tf.Tensor(5.8566504, shape=(), dtype=float32)\n",
            "Epoch  19 Loss =  tf.Tensor(5.7904654, shape=(), dtype=float32)\n",
            "Epoch  20 Loss =  tf.Tensor(5.723422, shape=(), dtype=float32)\n",
            "Epoch  21 Loss =  tf.Tensor(5.6557083, shape=(), dtype=float32)\n",
            "Epoch  22 Loss =  tf.Tensor(5.587278, shape=(), dtype=float32)\n",
            "Epoch  23 Loss =  tf.Tensor(5.518106, shape=(), dtype=float32)\n",
            "Epoch  24 Loss =  tf.Tensor(5.448163, shape=(), dtype=float32)\n",
            "Epoch  25 Loss =  tf.Tensor(5.3773503, shape=(), dtype=float32)\n",
            "Epoch  26 Loss =  tf.Tensor(5.3054795, shape=(), dtype=float32)\n",
            "Epoch  27 Loss =  tf.Tensor(5.2325263, shape=(), dtype=float32)\n",
            "Epoch  28 Loss =  tf.Tensor(5.158456, shape=(), dtype=float32)\n",
            "Epoch  29 Loss =  tf.Tensor(5.0835886, shape=(), dtype=float32)\n",
            "Epoch  30 Loss =  tf.Tensor(5.008045, shape=(), dtype=float32)\n",
            "Epoch  31 Loss =  tf.Tensor(4.93186, shape=(), dtype=float32)\n",
            "Epoch  32 Loss =  tf.Tensor(4.855384, shape=(), dtype=float32)\n",
            "Epoch  33 Loss =  tf.Tensor(4.7786207, shape=(), dtype=float32)\n",
            "Epoch  34 Loss =  tf.Tensor(4.70163, shape=(), dtype=float32)\n",
            "Epoch  35 Loss =  tf.Tensor(4.624522, shape=(), dtype=float32)\n",
            "Epoch  36 Loss =  tf.Tensor(4.547418, shape=(), dtype=float32)\n",
            "Epoch  37 Loss =  tf.Tensor(4.4704437, shape=(), dtype=float32)\n",
            "Epoch  38 Loss =  tf.Tensor(4.393684, shape=(), dtype=float32)\n",
            "Epoch  39 Loss =  tf.Tensor(4.3172746, shape=(), dtype=float32)\n",
            "Epoch  40 Loss =  tf.Tensor(4.24135, shape=(), dtype=float32)\n",
            "Epoch  41 Loss =  tf.Tensor(4.166027, shape=(), dtype=float32)\n",
            "Epoch  42 Loss =  tf.Tensor(4.0914288, shape=(), dtype=float32)\n",
            "Epoch  43 Loss =  tf.Tensor(4.017722, shape=(), dtype=float32)\n",
            "Epoch  44 Loss =  tf.Tensor(3.9450371, shape=(), dtype=float32)\n",
            "Epoch  45 Loss =  tf.Tensor(3.8735116, shape=(), dtype=float32)\n",
            "Epoch  46 Loss =  tf.Tensor(3.8032656, shape=(), dtype=float32)\n",
            "Epoch  47 Loss =  tf.Tensor(3.7344227, shape=(), dtype=float32)\n",
            "Epoch  48 Loss =  tf.Tensor(3.667097, shape=(), dtype=float32)\n",
            "Epoch  49 Loss =  tf.Tensor(3.6014018, shape=(), dtype=float32)\n",
            "Epoch  50 Loss =  tf.Tensor(3.5374413, shape=(), dtype=float32)\n",
            "Epoch  51 Loss =  tf.Tensor(3.4753072, shape=(), dtype=float32)\n",
            "Epoch  52 Loss =  tf.Tensor(3.4150817, shape=(), dtype=float32)\n",
            "Epoch  53 Loss =  tf.Tensor(3.3568451, shape=(), dtype=float32)\n",
            "Epoch  54 Loss =  tf.Tensor(3.3006706, shape=(), dtype=float32)\n",
            "Epoch  55 Loss =  tf.Tensor(3.2466187, shape=(), dtype=float32)\n",
            "Epoch  56 Loss =  tf.Tensor(3.194718, shape=(), dtype=float32)\n",
            "Epoch  57 Loss =  tf.Tensor(3.145001, shape=(), dtype=float32)\n",
            "Epoch  58 Loss =  tf.Tensor(3.0974922, shape=(), dtype=float32)\n",
            "Epoch  59 Loss =  tf.Tensor(3.052208, shape=(), dtype=float32)\n",
            "Epoch  60 Loss =  tf.Tensor(3.0091462, shape=(), dtype=float32)\n",
            "Epoch  61 Loss =  tf.Tensor(2.968309, shape=(), dtype=float32)\n",
            "Epoch  62 Loss =  tf.Tensor(2.9296954, shape=(), dtype=float32)\n",
            "Epoch  63 Loss =  tf.Tensor(2.893277, shape=(), dtype=float32)\n",
            "Epoch  64 Loss =  tf.Tensor(2.8590221, shape=(), dtype=float32)\n",
            "Epoch  65 Loss =  tf.Tensor(2.8269005, shape=(), dtype=float32)\n",
            "Epoch  66 Loss =  tf.Tensor(2.7968798, shape=(), dtype=float32)\n",
            "Epoch  67 Loss =  tf.Tensor(2.7689037, shape=(), dtype=float32)\n",
            "Epoch  68 Loss =  tf.Tensor(2.7429233, shape=(), dtype=float32)\n",
            "Epoch  69 Loss =  tf.Tensor(2.718883, shape=(), dtype=float32)\n",
            "Epoch  70 Loss =  tf.Tensor(2.696714, shape=(), dtype=float32)\n",
            "Epoch  71 Loss =  tf.Tensor(2.676354, shape=(), dtype=float32)\n",
            "Epoch  72 Loss =  tf.Tensor(2.6577344, shape=(), dtype=float32)\n",
            "Epoch  73 Loss =  tf.Tensor(2.6407795, shape=(), dtype=float32)\n",
            "Epoch  74 Loss =  tf.Tensor(2.6254072, shape=(), dtype=float32)\n",
            "Epoch  75 Loss =  tf.Tensor(2.611554, shape=(), dtype=float32)\n",
            "Epoch  76 Loss =  tf.Tensor(2.5991306, shape=(), dtype=float32)\n",
            "Epoch  77 Loss =  tf.Tensor(2.5880547, shape=(), dtype=float32)\n",
            "Epoch  78 Loss =  tf.Tensor(2.5782316, shape=(), dtype=float32)\n",
            "Epoch  79 Loss =  tf.Tensor(2.5695844, shape=(), dtype=float32)\n",
            "Epoch  80 Loss =  tf.Tensor(2.5620332, shape=(), dtype=float32)\n",
            "Epoch  81 Loss =  tf.Tensor(2.5554996, shape=(), dtype=float32)\n",
            "Epoch  82 Loss =  tf.Tensor(2.5498996, shape=(), dtype=float32)\n",
            "Epoch  83 Loss =  tf.Tensor(2.5451455, shape=(), dtype=float32)\n",
            "Epoch  84 Loss =  tf.Tensor(2.541164, shape=(), dtype=float32)\n",
            "Epoch  85 Loss =  tf.Tensor(2.537867, shape=(), dtype=float32)\n",
            "Epoch  86 Loss =  tf.Tensor(2.5351958, shape=(), dtype=float32)\n",
            "Epoch  87 Loss =  tf.Tensor(2.5330741, shape=(), dtype=float32)\n",
            "Epoch  88 Loss =  tf.Tensor(2.531421, shape=(), dtype=float32)\n",
            "Epoch  89 Loss =  tf.Tensor(2.5301685, shape=(), dtype=float32)\n",
            "Epoch  90 Loss =  tf.Tensor(2.5292592, shape=(), dtype=float32)\n",
            "Epoch  91 Loss =  tf.Tensor(2.5286357, shape=(), dtype=float32)\n",
            "Epoch  92 Loss =  tf.Tensor(2.5282419, shape=(), dtype=float32)\n",
            "Epoch  93 Loss =  tf.Tensor(2.5280294, shape=(), dtype=float32)\n",
            "Epoch  94 Loss =  tf.Tensor(2.5279553, shape=(), dtype=float32)\n",
            "Epoch  95 Loss =  tf.Tensor(2.527981, shape=(), dtype=float32)\n",
            "Epoch  96 Loss =  tf.Tensor(2.528072, shape=(), dtype=float32)\n",
            "Epoch  97 Loss =  tf.Tensor(2.5281982, shape=(), dtype=float32)\n",
            "Epoch  98 Loss =  tf.Tensor(2.5283375, shape=(), dtype=float32)\n",
            "Epoch  99 Loss =  tf.Tensor(2.5284727, shape=(), dtype=float32)\n",
            "Epoch  100 Loss =  tf.Tensor(2.5285883, shape=(), dtype=float32)\n",
            "Epoch  101 Loss =  tf.Tensor(2.5286713, shape=(), dtype=float32)\n",
            "Epoch  102 Loss =  tf.Tensor(2.5287151, shape=(), dtype=float32)\n",
            "Epoch  103 Loss =  tf.Tensor(2.5287144, shape=(), dtype=float32)\n",
            "Epoch  104 Loss =  tf.Tensor(2.5286634, shape=(), dtype=float32)\n",
            "Epoch  105 Loss =  tf.Tensor(2.5285692, shape=(), dtype=float32)\n",
            "Epoch  106 Loss =  tf.Tensor(2.5284307, shape=(), dtype=float32)\n",
            "Epoch  107 Loss =  tf.Tensor(2.5282478, shape=(), dtype=float32)\n",
            "Epoch  108 Loss =  tf.Tensor(2.528025, shape=(), dtype=float32)\n",
            "Epoch  109 Loss =  tf.Tensor(2.5277662, shape=(), dtype=float32)\n",
            "Epoch  110 Loss =  tf.Tensor(2.5274777, shape=(), dtype=float32)\n",
            "Epoch  111 Loss =  tf.Tensor(2.527163, shape=(), dtype=float32)\n",
            "Epoch  112 Loss =  tf.Tensor(2.526826, shape=(), dtype=float32)\n",
            "Epoch  113 Loss =  tf.Tensor(2.5264742, shape=(), dtype=float32)\n",
            "Epoch  114 Loss =  tf.Tensor(2.5261106, shape=(), dtype=float32)\n",
            "Epoch  115 Loss =  tf.Tensor(2.525741, shape=(), dtype=float32)\n",
            "Epoch  116 Loss =  tf.Tensor(2.5253677, shape=(), dtype=float32)\n",
            "Epoch  117 Loss =  tf.Tensor(2.5249944, shape=(), dtype=float32)\n",
            "Epoch  118 Loss =  tf.Tensor(2.5246248, shape=(), dtype=float32)\n",
            "Epoch  119 Loss =  tf.Tensor(2.5242615, shape=(), dtype=float32)\n",
            "Epoch  120 Loss =  tf.Tensor(2.5239055, shape=(), dtype=float32)\n",
            "Epoch  121 Loss =  tf.Tensor(2.5235589, shape=(), dtype=float32)\n",
            "Epoch  122 Loss =  tf.Tensor(2.5232224, shape=(), dtype=float32)\n",
            "Epoch  123 Loss =  tf.Tensor(2.5228996, shape=(), dtype=float32)\n",
            "Epoch  124 Loss =  tf.Tensor(2.5225897, shape=(), dtype=float32)\n",
            "Epoch  125 Loss =  tf.Tensor(2.5222921, shape=(), dtype=float32)\n",
            "Epoch  126 Loss =  tf.Tensor(2.5220094, shape=(), dtype=float32)\n",
            "Epoch  127 Loss =  tf.Tensor(2.521738, shape=(), dtype=float32)\n",
            "Epoch  128 Loss =  tf.Tensor(2.5214791, shape=(), dtype=float32)\n",
            "Epoch  129 Loss =  tf.Tensor(2.5212321, shape=(), dtype=float32)\n",
            "Epoch  130 Loss =  tf.Tensor(2.5209956, shape=(), dtype=float32)\n",
            "Epoch  131 Loss =  tf.Tensor(2.5207705, shape=(), dtype=float32)\n",
            "Epoch  132 Loss =  tf.Tensor(2.5205545, shape=(), dtype=float32)\n",
            "Epoch  133 Loss =  tf.Tensor(2.520349, shape=(), dtype=float32)\n",
            "Epoch  134 Loss =  tf.Tensor(2.5201545, shape=(), dtype=float32)\n",
            "Epoch  135 Loss =  tf.Tensor(2.519969, shape=(), dtype=float32)\n",
            "Epoch  136 Loss =  tf.Tensor(2.5197928, shape=(), dtype=float32)\n",
            "Epoch  137 Loss =  tf.Tensor(2.519623, shape=(), dtype=float32)\n",
            "Epoch  138 Loss =  tf.Tensor(2.5194569, shape=(), dtype=float32)\n",
            "Epoch  139 Loss =  tf.Tensor(2.5192976, shape=(), dtype=float32)\n",
            "Epoch  140 Loss =  tf.Tensor(2.5191436, shape=(), dtype=float32)\n",
            "Epoch  141 Loss =  tf.Tensor(2.5189915, shape=(), dtype=float32)\n",
            "Epoch  142 Loss =  tf.Tensor(2.5188432, shape=(), dtype=float32)\n",
            "Epoch  143 Loss =  tf.Tensor(2.518703, shape=(), dtype=float32)\n",
            "Epoch  144 Loss =  tf.Tensor(2.5185657, shape=(), dtype=float32)\n",
            "Epoch  145 Loss =  tf.Tensor(2.5184302, shape=(), dtype=float32)\n",
            "Epoch  146 Loss =  tf.Tensor(2.5182967, shape=(), dtype=float32)\n",
            "Epoch  147 Loss =  tf.Tensor(2.5181627, shape=(), dtype=float32)\n",
            "Epoch  148 Loss =  tf.Tensor(2.518033, shape=(), dtype=float32)\n",
            "Epoch  149 Loss =  tf.Tensor(2.5179062, shape=(), dtype=float32)\n",
            "Epoch  150 Loss =  tf.Tensor(2.5177789, shape=(), dtype=float32)\n",
            "Epoch  151 Loss =  tf.Tensor(2.5176501, shape=(), dtype=float32)\n",
            "Epoch  152 Loss =  tf.Tensor(2.5175238, shape=(), dtype=float32)\n",
            "Epoch  153 Loss =  tf.Tensor(2.5173998, shape=(), dtype=float32)\n",
            "Epoch  154 Loss =  tf.Tensor(2.5172794, shape=(), dtype=float32)\n",
            "Epoch  155 Loss =  tf.Tensor(2.5171623, shape=(), dtype=float32)\n",
            "Epoch  156 Loss =  tf.Tensor(2.5170462, shape=(), dtype=float32)\n",
            "Epoch  157 Loss =  tf.Tensor(2.5169306, shape=(), dtype=float32)\n",
            "Epoch  158 Loss =  tf.Tensor(2.5168152, shape=(), dtype=float32)\n",
            "Epoch  159 Loss =  tf.Tensor(2.5166984, shape=(), dtype=float32)\n",
            "Epoch  160 Loss =  tf.Tensor(2.516581, shape=(), dtype=float32)\n",
            "Epoch  161 Loss =  tf.Tensor(2.516464, shape=(), dtype=float32)\n",
            "Epoch  162 Loss =  tf.Tensor(2.5163476, shape=(), dtype=float32)\n",
            "Epoch  163 Loss =  tf.Tensor(2.516233, shape=(), dtype=float32)\n",
            "Epoch  164 Loss =  tf.Tensor(2.51612, shape=(), dtype=float32)\n",
            "Epoch  165 Loss =  tf.Tensor(2.5160084, shape=(), dtype=float32)\n",
            "Epoch  166 Loss =  tf.Tensor(2.5158978, shape=(), dtype=float32)\n",
            "Epoch  167 Loss =  tf.Tensor(2.51579, shape=(), dtype=float32)\n",
            "Epoch  168 Loss =  tf.Tensor(2.5156903, shape=(), dtype=float32)\n",
            "Epoch  169 Loss =  tf.Tensor(2.515593, shape=(), dtype=float32)\n",
            "Epoch  170 Loss =  tf.Tensor(2.5155, shape=(), dtype=float32)\n",
            "Epoch  171 Loss =  tf.Tensor(2.515411, shape=(), dtype=float32)\n",
            "Epoch  172 Loss =  tf.Tensor(2.5153208, shape=(), dtype=float32)\n",
            "Epoch  173 Loss =  tf.Tensor(2.5152273, shape=(), dtype=float32)\n",
            "Epoch  174 Loss =  tf.Tensor(2.5151303, shape=(), dtype=float32)\n",
            "Epoch  175 Loss =  tf.Tensor(2.5150232, shape=(), dtype=float32)\n",
            "Epoch  176 Loss =  tf.Tensor(2.5149064, shape=(), dtype=float32)\n",
            "Epoch  177 Loss =  tf.Tensor(2.5147903, shape=(), dtype=float32)\n",
            "Epoch  178 Loss =  tf.Tensor(2.5146713, shape=(), dtype=float32)\n",
            "Epoch  179 Loss =  tf.Tensor(2.5145402, shape=(), dtype=float32)\n",
            "Epoch  180 Loss =  tf.Tensor(2.5144143, shape=(), dtype=float32)\n",
            "Epoch  181 Loss =  tf.Tensor(2.5142987, shape=(), dtype=float32)\n",
            "Epoch  182 Loss =  tf.Tensor(2.514206, shape=(), dtype=float32)\n",
            "Epoch  183 Loss =  tf.Tensor(2.5140967, shape=(), dtype=float32)\n",
            "Epoch  184 Loss =  tf.Tensor(2.513963, shape=(), dtype=float32)\n",
            "Epoch  185 Loss =  tf.Tensor(2.5138006, shape=(), dtype=float32)\n",
            "Epoch  186 Loss =  tf.Tensor(2.5136197, shape=(), dtype=float32)\n",
            "Epoch  187 Loss =  tf.Tensor(2.5134041, shape=(), dtype=float32)\n",
            "Epoch  188 Loss =  tf.Tensor(2.513163, shape=(), dtype=float32)\n",
            "Epoch  189 Loss =  tf.Tensor(2.5129163, shape=(), dtype=float32)\n",
            "Epoch  190 Loss =  tf.Tensor(2.5126467, shape=(), dtype=float32)\n",
            "Epoch  191 Loss =  tf.Tensor(2.5123215, shape=(), dtype=float32)\n",
            "Epoch  192 Loss =  tf.Tensor(2.512001, shape=(), dtype=float32)\n",
            "Epoch  193 Loss =  tf.Tensor(2.5116622, shape=(), dtype=float32)\n",
            "Epoch  194 Loss =  tf.Tensor(2.5113103, shape=(), dtype=float32)\n",
            "Epoch  195 Loss =  tf.Tensor(2.5109076, shape=(), dtype=float32)\n",
            "Epoch  196 Loss =  tf.Tensor(2.5103836, shape=(), dtype=float32)\n",
            "Epoch  197 Loss =  tf.Tensor(2.5100813, shape=(), dtype=float32)\n",
            "Epoch  198 Loss =  tf.Tensor(2.5088105, shape=(), dtype=float32)\n",
            "Epoch  199 Loss =  tf.Tensor(2.5065958, shape=(), dtype=float32)\n",
            "Epoch  200 Loss =  tf.Tensor(2.4980345, shape=(), dtype=float32)\n",
            "Epoch  201 Loss =  tf.Tensor(2.5039227, shape=(), dtype=float32)\n",
            "Epoch  202 Loss =  tf.Tensor(2.495352, shape=(), dtype=float32)\n",
            "Epoch  203 Loss =  tf.Tensor(2.435435, shape=(), dtype=float32)\n",
            "Epoch  204 Loss =  tf.Tensor(2.3470674, shape=(), dtype=float32)\n",
            "Epoch  205 Loss =  tf.Tensor(2.366252, shape=(), dtype=float32)\n",
            "Epoch  206 Loss =  tf.Tensor(2.421216, shape=(), dtype=float32)\n",
            "Epoch  207 Loss =  tf.Tensor(2.2780137, shape=(), dtype=float32)\n",
            "Epoch  208 Loss =  tf.Tensor(2.201947, shape=(), dtype=float32)\n",
            "Epoch  209 Loss =  tf.Tensor(2.199191, shape=(), dtype=float32)\n",
            "Epoch  210 Loss =  tf.Tensor(2.1818676, shape=(), dtype=float32)\n",
            "Epoch  211 Loss =  tf.Tensor(2.1435301, shape=(), dtype=float32)\n",
            "Epoch  212 Loss =  tf.Tensor(2.0911272, shape=(), dtype=float32)\n",
            "Epoch  213 Loss =  tf.Tensor(2.0263968, shape=(), dtype=float32)\n",
            "Epoch  214 Loss =  tf.Tensor(2.00563, shape=(), dtype=float32)\n",
            "Epoch  215 Loss =  tf.Tensor(2.0644598, shape=(), dtype=float32)\n",
            "Epoch  216 Loss =  tf.Tensor(2.058848, shape=(), dtype=float32)\n",
            "Epoch  217 Loss =  tf.Tensor(2.013005, shape=(), dtype=float32)\n",
            "Epoch  218 Loss =  tf.Tensor(1.945551, shape=(), dtype=float32)\n",
            "Epoch  219 Loss =  tf.Tensor(1.8791491, shape=(), dtype=float32)\n",
            "Epoch  220 Loss =  tf.Tensor(1.8587961, shape=(), dtype=float32)\n",
            "Epoch  221 Loss =  tf.Tensor(1.8501962, shape=(), dtype=float32)\n",
            "Epoch  222 Loss =  tf.Tensor(1.7808568, shape=(), dtype=float32)\n",
            "Epoch  223 Loss =  tf.Tensor(1.7343268, shape=(), dtype=float32)\n",
            "Epoch  224 Loss =  tf.Tensor(1.6882265, shape=(), dtype=float32)\n",
            "Epoch  225 Loss =  tf.Tensor(1.6435342, shape=(), dtype=float32)\n",
            "Epoch  226 Loss =  tf.Tensor(1.6018082, shape=(), dtype=float32)\n",
            "Epoch  227 Loss =  tf.Tensor(1.5775442, shape=(), dtype=float32)\n",
            "Epoch  228 Loss =  tf.Tensor(1.5626688, shape=(), dtype=float32)\n",
            "Epoch  229 Loss =  tf.Tensor(1.5251865, shape=(), dtype=float32)\n",
            "Epoch  230 Loss =  tf.Tensor(1.4704593, shape=(), dtype=float32)\n",
            "Epoch  231 Loss =  tf.Tensor(1.4209871, shape=(), dtype=float32)\n",
            "Epoch  232 Loss =  tf.Tensor(1.3915478, shape=(), dtype=float32)\n",
            "Epoch  233 Loss =  tf.Tensor(1.3767402, shape=(), dtype=float32)\n",
            "Epoch  234 Loss =  tf.Tensor(1.3445083, shape=(), dtype=float32)\n",
            "Epoch  235 Loss =  tf.Tensor(1.301236, shape=(), dtype=float32)\n",
            "Epoch  236 Loss =  tf.Tensor(1.2847372, shape=(), dtype=float32)\n",
            "Epoch  237 Loss =  tf.Tensor(1.260721, shape=(), dtype=float32)\n",
            "Epoch  238 Loss =  tf.Tensor(1.2535708, shape=(), dtype=float32)\n",
            "Epoch  239 Loss =  tf.Tensor(1.2367196, shape=(), dtype=float32)\n",
            "Epoch  240 Loss =  tf.Tensor(1.22973, shape=(), dtype=float32)\n",
            "Epoch  241 Loss =  tf.Tensor(1.220696, shape=(), dtype=float32)\n",
            "Epoch  242 Loss =  tf.Tensor(1.2101775, shape=(), dtype=float32)\n",
            "Epoch  243 Loss =  tf.Tensor(1.2018459, shape=(), dtype=float32)\n",
            "Epoch  244 Loss =  tf.Tensor(1.1943836, shape=(), dtype=float32)\n",
            "Epoch  245 Loss =  tf.Tensor(1.1863242, shape=(), dtype=float32)\n",
            "Epoch  246 Loss =  tf.Tensor(1.178988, shape=(), dtype=float32)\n",
            "Epoch  247 Loss =  tf.Tensor(1.1708174, shape=(), dtype=float32)\n",
            "Epoch  248 Loss =  tf.Tensor(1.1623182, shape=(), dtype=float32)\n",
            "Epoch  249 Loss =  tf.Tensor(1.154213, shape=(), dtype=float32)\n",
            "Epoch  250 Loss =  tf.Tensor(1.1462171, shape=(), dtype=float32)\n",
            "Epoch  251 Loss =  tf.Tensor(1.1383487, shape=(), dtype=float32)\n",
            "Epoch  252 Loss =  tf.Tensor(1.1310129, shape=(), dtype=float32)\n",
            "Epoch  253 Loss =  tf.Tensor(1.1240709, shape=(), dtype=float32)\n",
            "Epoch  254 Loss =  tf.Tensor(1.1174052, shape=(), dtype=float32)\n",
            "Epoch  255 Loss =  tf.Tensor(1.1109273, shape=(), dtype=float32)\n",
            "Epoch  256 Loss =  tf.Tensor(1.105355, shape=(), dtype=float32)\n",
            "Epoch  257 Loss =  tf.Tensor(1.1002564, shape=(), dtype=float32)\n",
            "Epoch  258 Loss =  tf.Tensor(1.0955501, shape=(), dtype=float32)\n",
            "Epoch  259 Loss =  tf.Tensor(1.0911367, shape=(), dtype=float32)\n",
            "Epoch  260 Loss =  tf.Tensor(1.0869311, shape=(), dtype=float32)\n",
            "Epoch  261 Loss =  tf.Tensor(1.08299, shape=(), dtype=float32)\n",
            "Epoch  262 Loss =  tf.Tensor(1.0791155, shape=(), dtype=float32)\n",
            "Epoch  263 Loss =  tf.Tensor(1.0778966, shape=(), dtype=float32)\n",
            "Epoch  264 Loss =  tf.Tensor(1.075035, shape=(), dtype=float32)\n",
            "Epoch  265 Loss =  tf.Tensor(1.0706193, shape=(), dtype=float32)\n",
            "Epoch  266 Loss =  tf.Tensor(1.0688701, shape=(), dtype=float32)\n",
            "Epoch  267 Loss =  tf.Tensor(1.0671246, shape=(), dtype=float32)\n",
            "Epoch  268 Loss =  tf.Tensor(1.0655468, shape=(), dtype=float32)\n",
            "Epoch  269 Loss =  tf.Tensor(1.0640934, shape=(), dtype=float32)\n",
            "Epoch  270 Loss =  tf.Tensor(1.0627921, shape=(), dtype=float32)\n",
            "Epoch  271 Loss =  tf.Tensor(1.0615971, shape=(), dtype=float32)\n",
            "Epoch  272 Loss =  tf.Tensor(1.0604681, shape=(), dtype=float32)\n",
            "Epoch  273 Loss =  tf.Tensor(1.05941, shape=(), dtype=float32)\n",
            "Epoch  274 Loss =  tf.Tensor(1.0584373, shape=(), dtype=float32)\n",
            "Epoch  275 Loss =  tf.Tensor(1.057543, shape=(), dtype=float32)\n",
            "Epoch  276 Loss =  tf.Tensor(1.0567205, shape=(), dtype=float32)\n",
            "Epoch  277 Loss =  tf.Tensor(1.0559714, shape=(), dtype=float32)\n",
            "Epoch  278 Loss =  tf.Tensor(1.0552502, shape=(), dtype=float32)\n",
            "Epoch  279 Loss =  tf.Tensor(1.0542037, shape=(), dtype=float32)\n",
            "Epoch  280 Loss =  tf.Tensor(1.0539142, shape=(), dtype=float32)\n",
            "Epoch  281 Loss =  tf.Tensor(1.0534768, shape=(), dtype=float32)\n",
            "Epoch  282 Loss =  tf.Tensor(1.0532274, shape=(), dtype=float32)\n",
            "Epoch  283 Loss =  tf.Tensor(1.0528089, shape=(), dtype=float32)\n",
            "Epoch  284 Loss =  tf.Tensor(1.0523676, shape=(), dtype=float32)\n",
            "Epoch  285 Loss =  tf.Tensor(1.0519258, shape=(), dtype=float32)\n",
            "Epoch  286 Loss =  tf.Tensor(1.0514588, shape=(), dtype=float32)\n",
            "Epoch  287 Loss =  tf.Tensor(1.0509231, shape=(), dtype=float32)\n",
            "Epoch  288 Loss =  tf.Tensor(1.0503368, shape=(), dtype=float32)\n",
            "Epoch  289 Loss =  tf.Tensor(1.0497147, shape=(), dtype=float32)\n",
            "Epoch  290 Loss =  tf.Tensor(1.0490655, shape=(), dtype=float32)\n",
            "Epoch  291 Loss =  tf.Tensor(1.0484028, shape=(), dtype=float32)\n",
            "Epoch  292 Loss =  tf.Tensor(1.0477654, shape=(), dtype=float32)\n",
            "Epoch  293 Loss =  tf.Tensor(1.0472265, shape=(), dtype=float32)\n",
            "Epoch  294 Loss =  tf.Tensor(1.0467021, shape=(), dtype=float32)\n",
            "Epoch  295 Loss =  tf.Tensor(1.0461097, shape=(), dtype=float32)\n",
            "Epoch  296 Loss =  tf.Tensor(1.0454223, shape=(), dtype=float32)\n",
            "Epoch  297 Loss =  tf.Tensor(1.0445633, shape=(), dtype=float32)\n",
            "Epoch  298 Loss =  tf.Tensor(1.0437047, shape=(), dtype=float32)\n",
            "Epoch  299 Loss =  tf.Tensor(1.0427504, shape=(), dtype=float32)\n",
            "Epoch  300 Loss =  tf.Tensor(1.0420274, shape=(), dtype=float32)\n",
            "Epoch  301 Loss =  tf.Tensor(1.0414164, shape=(), dtype=float32)\n",
            "Epoch  302 Loss =  tf.Tensor(1.0408673, shape=(), dtype=float32)\n",
            "Epoch  303 Loss =  tf.Tensor(1.0403892, shape=(), dtype=float32)\n",
            "Epoch  304 Loss =  tf.Tensor(1.0400074, shape=(), dtype=float32)\n",
            "Epoch  305 Loss =  tf.Tensor(1.0396137, shape=(), dtype=float32)\n",
            "Epoch  306 Loss =  tf.Tensor(1.0392234, shape=(), dtype=float32)\n",
            "Epoch  307 Loss =  tf.Tensor(1.0388398, shape=(), dtype=float32)\n",
            "Epoch  308 Loss =  tf.Tensor(1.0384812, shape=(), dtype=float32)\n",
            "Epoch  309 Loss =  tf.Tensor(1.0381474, shape=(), dtype=float32)\n",
            "Epoch  310 Loss =  tf.Tensor(1.0378417, shape=(), dtype=float32)\n",
            "Epoch  311 Loss =  tf.Tensor(1.0375988, shape=(), dtype=float32)\n",
            "Epoch  312 Loss =  tf.Tensor(1.037386, shape=(), dtype=float32)\n",
            "Epoch  313 Loss =  tf.Tensor(1.0371788, shape=(), dtype=float32)\n",
            "Epoch  314 Loss =  tf.Tensor(1.0369413, shape=(), dtype=float32)\n",
            "Epoch  315 Loss =  tf.Tensor(1.0366445, shape=(), dtype=float32)\n",
            "Epoch  316 Loss =  tf.Tensor(1.0362928, shape=(), dtype=float32)\n",
            "Epoch  317 Loss =  tf.Tensor(1.0359126, shape=(), dtype=float32)\n",
            "Epoch  318 Loss =  tf.Tensor(1.0355425, shape=(), dtype=float32)\n",
            "Epoch  319 Loss =  tf.Tensor(1.0352087, shape=(), dtype=float32)\n",
            "Epoch  320 Loss =  tf.Tensor(1.0349188, shape=(), dtype=float32)\n",
            "Epoch  321 Loss =  tf.Tensor(1.0346694, shape=(), dtype=float32)\n",
            "Epoch  322 Loss =  tf.Tensor(1.0344543, shape=(), dtype=float32)\n",
            "Epoch  323 Loss =  tf.Tensor(1.0342433, shape=(), dtype=float32)\n",
            "Epoch  324 Loss =  tf.Tensor(1.0340927, shape=(), dtype=float32)\n",
            "Epoch  325 Loss =  tf.Tensor(1.0339446, shape=(), dtype=float32)\n",
            "Epoch  326 Loss =  tf.Tensor(1.0338087, shape=(), dtype=float32)\n",
            "Epoch  327 Loss =  tf.Tensor(1.033668, shape=(), dtype=float32)\n",
            "Epoch  328 Loss =  tf.Tensor(1.0335176, shape=(), dtype=float32)\n",
            "Epoch  329 Loss =  tf.Tensor(1.0333656, shape=(), dtype=float32)\n",
            "Epoch  330 Loss =  tf.Tensor(1.0332232, shape=(), dtype=float32)\n",
            "Epoch  331 Loss =  tf.Tensor(1.0330923, shape=(), dtype=float32)\n",
            "Epoch  332 Loss =  tf.Tensor(1.0329587, shape=(), dtype=float32)\n",
            "Epoch  333 Loss =  tf.Tensor(1.0328157, shape=(), dtype=float32)\n",
            "Epoch  334 Loss =  tf.Tensor(1.0326793, shape=(), dtype=float32)\n",
            "Epoch  335 Loss =  tf.Tensor(1.0325558, shape=(), dtype=float32)\n",
            "Epoch  336 Loss =  tf.Tensor(1.0324345, shape=(), dtype=float32)\n",
            "Epoch  337 Loss =  tf.Tensor(1.0323024, shape=(), dtype=float32)\n",
            "Epoch  338 Loss =  tf.Tensor(1.0321606, shape=(), dtype=float32)\n",
            "Epoch  339 Loss =  tf.Tensor(1.0320354, shape=(), dtype=float32)\n",
            "Epoch  340 Loss =  tf.Tensor(1.031918, shape=(), dtype=float32)\n",
            "Epoch  341 Loss =  tf.Tensor(1.03181, shape=(), dtype=float32)\n",
            "Epoch  342 Loss =  tf.Tensor(1.0317059, shape=(), dtype=float32)\n",
            "Epoch  343 Loss =  tf.Tensor(1.0315821, shape=(), dtype=float32)\n",
            "Epoch  344 Loss =  tf.Tensor(1.0314686, shape=(), dtype=float32)\n",
            "Epoch  345 Loss =  tf.Tensor(1.0313694, shape=(), dtype=float32)\n",
            "Epoch  346 Loss =  tf.Tensor(1.0312891, shape=(), dtype=float32)\n",
            "Epoch  347 Loss =  tf.Tensor(1.031225, shape=(), dtype=float32)\n",
            "Epoch  348 Loss =  tf.Tensor(1.0311754, shape=(), dtype=float32)\n",
            "Epoch  349 Loss =  tf.Tensor(1.0311316, shape=(), dtype=float32)\n",
            "Epoch  350 Loss =  tf.Tensor(1.0310947, shape=(), dtype=float32)\n",
            "Epoch  351 Loss =  tf.Tensor(1.0310712, shape=(), dtype=float32)\n",
            "Epoch  352 Loss =  tf.Tensor(1.0310628, shape=(), dtype=float32)\n",
            "Epoch  353 Loss =  tf.Tensor(1.0310637, shape=(), dtype=float32)\n",
            "Epoch  354 Loss =  tf.Tensor(1.031107, shape=(), dtype=float32)\n",
            "Epoch  355 Loss =  tf.Tensor(1.0311462, shape=(), dtype=float32)\n",
            "Epoch  356 Loss =  tf.Tensor(1.0312443, shape=(), dtype=float32)\n",
            "Epoch  357 Loss =  tf.Tensor(1.0313826, shape=(), dtype=float32)\n",
            "Epoch  358 Loss =  tf.Tensor(1.0315819, shape=(), dtype=float32)\n",
            "Epoch  359 Loss =  tf.Tensor(1.0318251, shape=(), dtype=float32)\n",
            "Epoch  360 Loss =  tf.Tensor(1.0321, shape=(), dtype=float32)\n",
            "Epoch  361 Loss =  tf.Tensor(1.0323517, shape=(), dtype=float32)\n",
            "Epoch  362 Loss =  tf.Tensor(1.0326041, shape=(), dtype=float32)\n",
            "Epoch  363 Loss =  tf.Tensor(1.0328774, shape=(), dtype=float32)\n",
            "Epoch  364 Loss =  tf.Tensor(1.0330765, shape=(), dtype=float32)\n",
            "Epoch  365 Loss =  tf.Tensor(1.0332761, shape=(), dtype=float32)\n",
            "Epoch  366 Loss =  tf.Tensor(1.0336082, shape=(), dtype=float32)\n",
            "Epoch  367 Loss =  tf.Tensor(1.0341873, shape=(), dtype=float32)\n",
            "Epoch  368 Loss =  tf.Tensor(1.0350769, shape=(), dtype=float32)\n",
            "Epoch  369 Loss =  tf.Tensor(1.0360492, shape=(), dtype=float32)\n",
            "Epoch  370 Loss =  tf.Tensor(1.0367568, shape=(), dtype=float32)\n",
            "Epoch  371 Loss =  tf.Tensor(1.0372401, shape=(), dtype=float32)\n",
            "Epoch  372 Loss =  tf.Tensor(1.0376475, shape=(), dtype=float32)\n",
            "Epoch  373 Loss =  tf.Tensor(1.0381832, shape=(), dtype=float32)\n",
            "Epoch  374 Loss =  tf.Tensor(1.0388064, shape=(), dtype=float32)\n",
            "Epoch  375 Loss =  tf.Tensor(1.0393398, shape=(), dtype=float32)\n",
            "Epoch  376 Loss =  tf.Tensor(1.039603, shape=(), dtype=float32)\n",
            "Epoch  377 Loss =  tf.Tensor(1.0396343, shape=(), dtype=float32)\n",
            "Epoch  378 Loss =  tf.Tensor(1.0394012, shape=(), dtype=float32)\n",
            "Epoch  379 Loss =  tf.Tensor(1.0390115, shape=(), dtype=float32)\n",
            "Epoch  380 Loss =  tf.Tensor(1.0385838, shape=(), dtype=float32)\n",
            "Epoch  381 Loss =  tf.Tensor(1.0381773, shape=(), dtype=float32)\n",
            "Epoch  382 Loss =  tf.Tensor(1.0377407, shape=(), dtype=float32)\n",
            "Epoch  383 Loss =  tf.Tensor(1.0372739, shape=(), dtype=float32)\n",
            "Epoch  384 Loss =  tf.Tensor(1.0365845, shape=(), dtype=float32)\n",
            "Epoch  385 Loss =  tf.Tensor(1.0354898, shape=(), dtype=float32)\n",
            "Epoch  386 Loss =  tf.Tensor(1.0341567, shape=(), dtype=float32)\n",
            "Epoch  387 Loss =  tf.Tensor(1.0326374, shape=(), dtype=float32)\n",
            "Epoch  388 Loss =  tf.Tensor(1.0312138, shape=(), dtype=float32)\n",
            "Epoch  389 Loss =  tf.Tensor(1.0303117, shape=(), dtype=float32)\n",
            "Epoch  390 Loss =  tf.Tensor(1.0295041, shape=(), dtype=float32)\n",
            "Epoch  391 Loss =  tf.Tensor(1.0289376, shape=(), dtype=float32)\n",
            "Epoch  392 Loss =  tf.Tensor(1.028468, shape=(), dtype=float32)\n",
            "Epoch  393 Loss =  tf.Tensor(1.0280728, shape=(), dtype=float32)\n",
            "Epoch  394 Loss =  tf.Tensor(1.0277454, shape=(), dtype=float32)\n",
            "Epoch  395 Loss =  tf.Tensor(1.0274606, shape=(), dtype=float32)\n",
            "Epoch  396 Loss =  tf.Tensor(1.0271964, shape=(), dtype=float32)\n",
            "Epoch  397 Loss =  tf.Tensor(1.0269457, shape=(), dtype=float32)\n",
            "Epoch  398 Loss =  tf.Tensor(1.0267018, shape=(), dtype=float32)\n",
            "Epoch  399 Loss =  tf.Tensor(1.0264614, shape=(), dtype=float32)\n",
            "Epoch  400 Loss =  tf.Tensor(1.0262222, shape=(), dtype=float32)\n",
            "Epoch  401 Loss =  tf.Tensor(1.0259842, shape=(), dtype=float32)\n",
            "Epoch  402 Loss =  tf.Tensor(1.0257475, shape=(), dtype=float32)\n",
            "Epoch  403 Loss =  tf.Tensor(1.0255135, shape=(), dtype=float32)\n",
            "Epoch  404 Loss =  tf.Tensor(1.0252849, shape=(), dtype=float32)\n",
            "Epoch  405 Loss =  tf.Tensor(1.0250628, shape=(), dtype=float32)\n",
            "Epoch  406 Loss =  tf.Tensor(1.0248494, shape=(), dtype=float32)\n",
            "Epoch  407 Loss =  tf.Tensor(1.0246463, shape=(), dtype=float32)\n",
            "Epoch  408 Loss =  tf.Tensor(1.0244545, shape=(), dtype=float32)\n",
            "Epoch  409 Loss =  tf.Tensor(1.0242746, shape=(), dtype=float32)\n",
            "Epoch  410 Loss =  tf.Tensor(1.0241084, shape=(), dtype=float32)\n",
            "Epoch  411 Loss =  tf.Tensor(1.0239568, shape=(), dtype=float32)\n",
            "Epoch  412 Loss =  tf.Tensor(1.0238165, shape=(), dtype=float32)\n",
            "Epoch  413 Loss =  tf.Tensor(1.023721, shape=(), dtype=float32)\n",
            "Epoch  414 Loss =  tf.Tensor(1.0236642, shape=(), dtype=float32)\n",
            "Epoch  415 Loss =  tf.Tensor(1.0236394, shape=(), dtype=float32)\n",
            "Epoch  416 Loss =  tf.Tensor(1.023637, shape=(), dtype=float32)\n",
            "Epoch  417 Loss =  tf.Tensor(1.023648, shape=(), dtype=float32)\n",
            "Epoch  418 Loss =  tf.Tensor(1.0236634, shape=(), dtype=float32)\n",
            "Epoch  419 Loss =  tf.Tensor(1.0236762, shape=(), dtype=float32)\n",
            "Epoch  420 Loss =  tf.Tensor(1.0236807, shape=(), dtype=float32)\n",
            "Epoch  421 Loss =  tf.Tensor(1.0236733, shape=(), dtype=float32)\n",
            "Epoch  422 Loss =  tf.Tensor(1.0236497, shape=(), dtype=float32)\n",
            "Epoch  423 Loss =  tf.Tensor(1.0236101, shape=(), dtype=float32)\n",
            "Epoch  424 Loss =  tf.Tensor(1.0235543, shape=(), dtype=float32)\n",
            "Epoch  425 Loss =  tf.Tensor(1.0234832, shape=(), dtype=float32)\n",
            "Epoch  426 Loss =  tf.Tensor(1.0233985, shape=(), dtype=float32)\n",
            "Epoch  427 Loss =  tf.Tensor(1.023303, shape=(), dtype=float32)\n",
            "Epoch  428 Loss =  tf.Tensor(1.023201, shape=(), dtype=float32)\n",
            "Epoch  429 Loss =  tf.Tensor(1.0230896, shape=(), dtype=float32)\n",
            "Epoch  430 Loss =  tf.Tensor(1.0229734, shape=(), dtype=float32)\n",
            "Epoch  431 Loss =  tf.Tensor(1.0228547, shape=(), dtype=float32)\n",
            "Epoch  432 Loss =  tf.Tensor(1.022737, shape=(), dtype=float32)\n",
            "Epoch  433 Loss =  tf.Tensor(1.0226228, shape=(), dtype=float32)\n",
            "Epoch  434 Loss =  tf.Tensor(1.0225142, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-1d4ee56556b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-9d31d716c52e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mto_backprop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstabilisation_check\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-f9abb875ec63>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(result, neigh, feature, eval_logic, log_enable)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neighbour Aggregation = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_logic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m    420\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 421\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    451\u001b[0m           \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m           zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0;31m# This is a dummy tensor for testing purpose.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4523\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4525\u001b[0;31m           **while_loop_kwargs)\n\u001b[0m\u001b[1;32m   4526\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         output, new_states = step_function(current_input,\n\u001b[0;32m-> 4509\u001b[0;31m                                            tuple(states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m         \u001b[0mflat_new_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       last_output, outputs, states = backend.rnn(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0mmatrix_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m           \u001b[0mmatrix_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0;31m# hidden state projected separately for update/reset and new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(x, bias, data_format)\u001b[0m\n\u001b[1;32m   5997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5998\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5999\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NHWC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6000\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6001\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3346\u001b[0m     \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0mdimension\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m   \"\"\"\n\u001b[0;32m-> 3348\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LDTXF5knmGv",
        "outputId": "1ae4fa85-c042-4866-bfb1-fe77edfd056f"
      },
      "source": [
        "feature_validation = tf.constant([\n",
        "                     [1], \n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0],\n",
        "                     [0]\n",
        "                    ], dtype=tf.float32)\n",
        "output_validation = tf.constant([\n",
        "                     [-1.0], \n",
        "                     [-1.0],\n",
        "                     [-1.0],\n",
        "                     [-1.0],\n",
        "                     [-1.0]\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
        "input_validation = input_validation[:,tf.newaxis, :]\n",
        "neigh_validation = tf.constant([\n",
        "                     [0, 1, 0, 0, 0], \n",
        "                     [1, 0, 1, 0, 0],\n",
        "                     [0, 1, 0, 1, 0],\n",
        "                     [0, 0, 1, 0, 1],\n",
        "                     [0, 0, 0, 1, 0],\n",
        "                    ], dtype=tf.float32)\n",
        "\n",
        "change_model = create_model(input_validation.shape, instantiate_layers())\n",
        "change_model.set_weights(model.get_weights())\n",
        "\n",
        "result_validation = input_validation\n",
        "model.reset_states()\n",
        "for i in range(20):\n",
        "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, True)\n",
        "print(result_validation)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input =  tf.Tensor(\n",
            "[[[ 1. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]\n",
            "\n",
            " [[ 0. -1.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        0.312784 ]\n",
            " [0.        0.3249696]\n",
            " [0.        0.3249696]\n",
            " [0.        0.3249696]\n",
            " [0.        0.3249696]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        0.312784 ]]\n",
            "\n",
            " [[0.        0.3249696]]\n",
            "\n",
            " [[0.        0.3249696]]\n",
            "\n",
            " [[0.        0.3249696]]\n",
            "\n",
            " [[0.        0.3249696]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        0.9427563]\n",
            " [0.        1.0059458]\n",
            " [0.        1.0059458]\n",
            " [0.        1.0059458]\n",
            " [0.        1.0059458]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        0.9427563]]\n",
            "\n",
            " [[0.        1.0059458]]\n",
            "\n",
            " [[0.        1.0059458]]\n",
            "\n",
            " [[0.        1.0059458]]\n",
            "\n",
            " [[0.        1.0059458]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        1.4222239]\n",
            " [0.        1.513028 ]\n",
            " [0.        1.513028 ]\n",
            " [0.        1.513028 ]\n",
            " [0.        1.5130281]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        1.4222239]]\n",
            "\n",
            " [[0.        1.513028 ]]\n",
            "\n",
            " [[0.        1.513028 ]]\n",
            "\n",
            " [[0.        1.513028 ]]\n",
            "\n",
            " [[0.        1.5130281]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        1.6920761]\n",
            " [0.        1.7966547]\n",
            " [0.        1.7966547]\n",
            " [0.        1.7966547]\n",
            " [0.        1.7966547]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        1.6920761]]\n",
            "\n",
            " [[0.        1.7966547]]\n",
            "\n",
            " [[0.        1.7966547]]\n",
            "\n",
            " [[0.        1.7966547]]\n",
            "\n",
            " [[0.        1.7966547]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        1.8134674]\n",
            " [0.        1.9470348]\n",
            " [0.        1.9470348]\n",
            " [0.        1.9470348]\n",
            " [0.        1.9470348]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        1.8134674]]\n",
            "\n",
            " [[0.        1.9470348]]\n",
            "\n",
            " [[0.        1.9470348]]\n",
            "\n",
            " [[0.        1.9470348]]\n",
            "\n",
            " [[0.        1.9470348]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        1.7705851]\n",
            " [0.        2.0217693]\n",
            " [0.        2.0217693]\n",
            " [0.        2.0217693]\n",
            " [0.        2.0217693]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        1.7705851]]\n",
            "\n",
            " [[0.        2.0217693]]\n",
            "\n",
            " [[0.        2.0217693]]\n",
            "\n",
            " [[0.        2.0217693]]\n",
            "\n",
            " [[0.        2.0217693]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        1.4817342]\n",
            " [0.        2.056859 ]\n",
            " [0.        2.056859 ]\n",
            " [0.        2.056859 ]\n",
            " [0.        2.056859 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        1.4817342]]\n",
            "\n",
            " [[0.        2.056859 ]]\n",
            "\n",
            " [[0.        2.056859 ]]\n",
            "\n",
            " [[0.        2.056859 ]]\n",
            "\n",
            " [[0.        2.056859 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.        0.9485839]\n",
            " [0.        2.0725107]\n",
            " [0.        2.0725107]\n",
            " [0.        2.0725107]\n",
            " [0.        2.0725107]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.        0.9485839]]\n",
            "\n",
            " [[0.        2.0725107]]\n",
            "\n",
            " [[0.        2.0725107]]\n",
            "\n",
            " [[0.        2.0725107]]\n",
            "\n",
            " [[0.        2.0725107]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.         0.45176047]\n",
            " [0.         2.0790043 ]\n",
            " [0.         2.0790043 ]\n",
            " [0.         2.0790043 ]\n",
            " [0.         2.0790043 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.         0.45176047]]\n",
            "\n",
            " [[0.         2.0790043 ]]\n",
            "\n",
            " [[0.         2.0790043 ]]\n",
            "\n",
            " [[0.         2.0790043 ]]\n",
            "\n",
            " [[0.         2.0790043 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.         0.19407982]\n",
            " [0.         2.0811214 ]\n",
            " [0.         2.0811214 ]\n",
            " [0.         2.0811214 ]\n",
            " [0.         2.0811214 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.         0.19407982]]\n",
            "\n",
            " [[0.         2.0811214 ]]\n",
            "\n",
            " [[0.         2.0811214 ]]\n",
            "\n",
            " [[0.         2.0811214 ]]\n",
            "\n",
            " [[0.         2.0811214 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[1.         0.04492993]\n",
            " [0.         2.080808  ]\n",
            " [0.         2.080808  ]\n",
            " [0.         2.080808  ]\n",
            " [0.         2.080808  ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[1.         0.04492993]]\n",
            "\n",
            " [[0.         2.080808  ]]\n",
            "\n",
            " [[0.         2.080808  ]]\n",
            "\n",
            " [[0.         2.080808  ]]\n",
            "\n",
            " [[0.         2.080808  ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[1. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]\n",
            "\n",
            " [[0. 0.]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.03862881]\n",
            " [ 0.          2.078453  ]\n",
            " [ 0.          2.078453  ]\n",
            " [ 0.          2.078453  ]\n",
            " [ 0.          2.078453  ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.03862881]]\n",
            "\n",
            " [[ 0.          2.078453  ]]\n",
            "\n",
            " [[ 0.          2.078453  ]]\n",
            "\n",
            " [[ 0.          2.078453  ]]\n",
            "\n",
            " [[ 0.          2.078453  ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.03862881]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.09421463]\n",
            " [ 0.          2.0733812 ]\n",
            " [ 0.          2.073381  ]\n",
            " [ 0.          2.073381  ]\n",
            " [ 0.          2.073381  ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.09421463]]\n",
            "\n",
            " [[ 0.          2.0733812 ]]\n",
            "\n",
            " [[ 0.          2.073381  ]]\n",
            "\n",
            " [[ 0.          2.073381  ]]\n",
            "\n",
            " [[ 0.          2.073381  ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.09421463]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.13507414]\n",
            " [ 0.          2.0626001 ]\n",
            " [ 0.          2.0625956 ]\n",
            " [ 0.          2.0625956 ]\n",
            " [ 0.          2.0625956 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.13507414]]\n",
            "\n",
            " [[ 0.          2.0626001 ]]\n",
            "\n",
            " [[ 0.          2.0625956 ]]\n",
            "\n",
            " [[ 0.          2.0625956 ]]\n",
            "\n",
            " [[ 0.          2.0625956 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.13507414]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.16711439]\n",
            " [ 0.          2.0325487 ]\n",
            " [ 0.          2.0324957 ]\n",
            " [ 0.          2.0324957 ]\n",
            " [ 0.          2.0324955 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.16711439]]\n",
            "\n",
            " [[ 0.          2.0325487 ]]\n",
            "\n",
            " [[ 0.          2.0324957 ]]\n",
            "\n",
            " [[ 0.          2.0324957 ]]\n",
            "\n",
            " [[ 0.          2.0324955 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.16711439]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.19339147]\n",
            " [ 0.          1.911442  ]\n",
            " [ 0.          1.9110186 ]\n",
            " [ 0.          1.9110186 ]\n",
            " [ 0.          1.9110183 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.19339147]]\n",
            "\n",
            " [[ 0.          1.911442  ]]\n",
            "\n",
            " [[ 0.          1.9110186 ]]\n",
            "\n",
            " [[ 0.          1.9110186 ]]\n",
            "\n",
            " [[ 0.          1.9110183 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.19339147]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.21565427]\n",
            " [ 0.          1.5646002 ]\n",
            " [ 0.          1.5633866 ]\n",
            " [ 0.          1.5633866 ]\n",
            " [ 0.          1.5633864 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.21565427]]\n",
            "\n",
            " [[ 0.          1.5646002 ]]\n",
            "\n",
            " [[ 0.          1.5633866 ]]\n",
            "\n",
            " [[ 0.          1.5633866 ]]\n",
            "\n",
            " [[ 0.          1.5633864 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.21565427]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.2349799 ]\n",
            " [ 0.          0.96405125]\n",
            " [ 0.          0.962159  ]\n",
            " [ 0.          0.962159  ]\n",
            " [ 0.          0.9621585 ]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.2349799 ]]\n",
            "\n",
            " [[ 0.          0.96405125]]\n",
            "\n",
            " [[ 0.          0.962159  ]]\n",
            "\n",
            " [[ 0.          0.962159  ]]\n",
            "\n",
            " [[ 0.          0.9621585 ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.         0.       ]]\n",
            "\n",
            " [[ 0.        -0.2349799]]\n",
            "\n",
            " [[ 0.         0.       ]]\n",
            "\n",
            " [[ 0.         0.       ]]\n",
            "\n",
            " [[ 0.         0.       ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.25207013]\n",
            " [ 0.          0.43357778]\n",
            " [ 0.          0.4323566 ]\n",
            " [ 0.          0.4323566 ]\n",
            " [ 0.          0.43235636]], shape=(5, 2), dtype=float32)\n",
            "Input =  tf.Tensor(\n",
            "[[[ 1.         -0.25207013]]\n",
            "\n",
            " [[ 0.          0.43357778]]\n",
            "\n",
            " [[ 0.          0.4323566 ]]\n",
            "\n",
            " [[ 0.          0.4323566 ]]\n",
            "\n",
            " [[ 0.          0.43235636]]], shape=(5, 1, 2), dtype=float32)\n",
            "Neighbour Aggregation =  tf.Tensor(\n",
            "[[[ 1.          0.        ]]\n",
            "\n",
            " [[ 0.         -0.25207013]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]\n",
            "\n",
            " [[ 0.          0.        ]]], shape=(5, 1, 2), dtype=float32)\n",
            "Output =  tf.Tensor(\n",
            "[[ 1.         -0.2674033 ]\n",
            " [ 0.          0.1721754 ]\n",
            " [ 0.          0.17121866]\n",
            " [ 0.          0.17121866]\n",
            " [ 0.          0.17121854]], shape=(5, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 1.         -0.2674033 ]]\n",
            "\n",
            " [[ 0.          0.1721754 ]]\n",
            "\n",
            " [[ 0.          0.17121866]]\n",
            "\n",
            " [[ 0.          0.17121866]]\n",
            "\n",
            " [[ 0.          0.17121854]]], shape=(5, 1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}