{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/test_with_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji2Yp08lPMHJ"
   },
   "source": [
    "# Neural Networks applied in Aggregate Computing\n",
    "In this notebook, I tried to apply Neural Network and Recurrent Neural Networks (RNN) in the context of Aggregate Computing (AC).\n",
    "\n",
    "## Model\n",
    "\n",
    "Usually, RNN are trained in indipendent sequences. In case of Aggregate Computing, the temporal sequence are correlated with each other following a neighbourhood policy. \n",
    "\n",
    "The key idea here is:\n",
    "- express the system as a graph. Offline we can imagine to access to the entire system\n",
    "- in each time step, we aggregate data from the neighbours and then we use RNN to compute the right output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tihJbe7wP_L7"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ld4IkeCHdg9f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from numpy.random import seed\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCXGw5707Rv7"
   },
   "source": [
    "# Simple Graph\n",
    "\n",
    "In this model, I model graph as:\n",
    "$G = (N, E)$\n",
    "\n",
    "Where, $N$ contains a feature vector and an output vector.\n",
    "\n",
    "$E$ is expressed as adjacency matrix, so: $E_{i,j} = 1$ iff $i$ is neighbour of $j$.\n",
    "\n",
    "Input is a matrix contains the concatenation of feature vector and output vector, something like: $ I(n) = <f(n), o(n)>$.\n",
    "Where $<a, b, c>$ means the column-wise fector concatenation. \n",
    "For instance, giving a vector $a = [1, 2]$ and $b = [2, 3]$, $<a,b> = [1, 2, 2, 3]$.\n",
    "\n",
    "The neighbour aggregation data can be computed leveraging matrix multiplication --- so increasing traning performance.\n",
    "$$ reduction(E * F) $$\n",
    "Where F contains all node features.\n",
    "$reduction$ is a multiset function (e.g. summation, mean,...).\n",
    "\n",
    "Pay attention, this model can be easly used in a decentralized situation.\n",
    "Indeed, the data aggregation will be done without global adjency matrix but only retrieving neighbour data. The dense layer already works locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DaicADIO7U34"
   },
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "input = tf.concat([feature, output], axis = 1)\n",
    "input = input[:,tf.newaxis, :]\n",
    "\n",
    "neigh = tf.constant([\n",
    "                     [n, 1, n, n], \n",
    "                     [1, n, 1, n],\n",
    "                     [n, 1, n, 1],\n",
    "                     [n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "ground = tf.constant([\n",
    "                     [0], \n",
    "                     [1],\n",
    "                     [2],\n",
    "                     [3],\n",
    "                    ], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRY-rUZ27Y0E"
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "Taking the output of previous step, adjecency matrix, and feature vector, this function compute the value of the next evaluation.\n",
    "So\n",
    "1. compute neighbourhood feature via aggregation\n",
    "2. concat neighbourhood feature with local feature and previous output\n",
    "3. perform a forward pass of a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UKorlgUN7arq"
   },
   "outputs": [],
   "source": [
    "def forward(result, neigh, feature, model, log_enable=False):\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  reshape = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  neigh_evaluation = tf.reduce_min(tf.multiply(neigh, reshape), 1) ## pass reduction strategy\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, feature.shape[:2]) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJqP660S5W4"
   },
   "source": [
    "# Model creation\n",
    "Create a sequential model given layers and the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CdXR3Tb3TV8l"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, layers):\n",
    "  input_layer = tf.keras.layers.InputLayer(input_shape=input_shape[1:], batch_size=input_shape[0])\n",
    "  layers.insert(0, input_layer)\n",
    "  return tf.keras.Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOdTAPsnGEf"
   },
   "source": [
    "## Recurrent model\n",
    "Simple network creation with multiple recurrent layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8oNvEE-Bh4B1"
   },
   "outputs": [],
   "source": [
    "def instantiate_layers(output_count = 1):\n",
    "  return [\n",
    "    tf.keras.layers.GRU(units = 4, activation='relu', return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.GRU(units = output_count, activation='relu', return_sequences=False, stateful=True, bias_initializer='ones'),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLAigDrToouO"
   },
   "source": [
    "## Linear Model\n",
    "Simple network with multiple linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9DneyuoJoltR"
   },
   "outputs": [],
   "source": [
    "def instantiate_linear_layers(output_count = 1):\n",
    "  uniform = tf.keras.initializers.GlorotNormal()\n",
    "  return [\n",
    "    tf.keras.layers.Dense(units = 32, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    tf.keras.layers.Dense(units = 16, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    tf.keras.layers.Dense(units = 8, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    tf.keras.layers.Dense(units = 4, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    tf.keras.layers.Dense(units = output_count, activation='selu', kernel_initializer='lecun_normal',bias_initializer='ones')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2iXarjQrq10"
   },
   "source": [
    "## Model instatiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JFidlC53rvyL"
   },
   "outputs": [],
   "source": [
    "linear = \"linear\"\n",
    "recurrent = \"recurrent\"\n",
    "same = \"same\"\n",
    "\n",
    "def instatiate(input, mode = \"same\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return create_model(input.shape, instantiate_linear_layers(output_count))\n",
    "  elif mode == recurrent:\n",
    "    return create_model(input.shape, instantiate_layers(output_count))\n",
    "\n",
    "def copy_model(model, mode = \"same\", input = \"\", output_count = 1):\n",
    "  if mode == linear:\n",
    "    return model\n",
    "  elif mode == recurrent:\n",
    "    change_model = instatiate(input, recurrent, output_count)\n",
    "    change_model.set_weights(model.get_weights())\n",
    "    return change_model\n",
    "mode = linear\n",
    "model = instatiate(input, linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZquNuutUD-n"
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xvzeO1W3UGi4"
   },
   "outputs": [],
   "source": [
    "## TODO pass input and network\n",
    "def train(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each=100, verbose=False):\n",
    "  input, neigh, feature, ground = data\n",
    "  for j in range(iteration):\n",
    "    with tf.GradientTape() as tape:\n",
    "      result = input\n",
    "      to_backprop = 0\n",
    "      for i in range(stabilise_in):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "      for i in range(stabilisation_check):\n",
    "        result = forward_fn(result, neigh, feature, model)\n",
    "        to_backprop += 1 / stabilisation_check * loss(ground, result[:, 0, 1:2])\n",
    "      model.reset_states()\n",
    "      \n",
    "      gradient = tape.gradient(to_backprop, model.weights)\n",
    "      optimizer.apply_gradients(zip(gradient, model.weights))\n",
    "    if(j % each == 0):\n",
    "      if(verbose == True):\n",
    "        partial_result = result[:, 0, 1:2]\n",
    "        tf.print(\"Ground truth: \\n\", tf.reshape(ground, ground.shape[0]))\n",
    "        tf.print(\"Current prediciton \\n\", tf.reshape(partial_result, result.shape[0]))\n",
    "        tf.print(\"Full output \\n\", result)\n",
    "      model.save('epoch/model_dense_' + str(j))\n",
    "      print(\"Epoch \", j ,\"Loss = \", tf.reduce_sum(to_backprop).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFGPPgD_hdHi"
   },
   "source": [
    "\n",
    "## Train loop\n",
    "Here I want only to find a function that overfits, so it solve this specific problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56wyzp3MdzYy",
    "outputId": "16270c05-acb3-40a5-cd24-f5a114f12706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epoch/model_dense_0/assets\n",
      "Epoch  0 Loss =  8.057685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29231d3cf1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilise_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstabilisation_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e45a9f9b0c3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, forward_fn, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, each, verbose)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstabilisation_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mto_backprop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstabilisation_check\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1196\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2340\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2368\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2369\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m       gen_math_ops.mean(\n\u001b[0m\u001b[1;32m   2371\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m           name=name))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   5760\u001b[0m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5761\u001b[0m   \u001b[0mtld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5762\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5763\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5764\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "model = instatiate(input, mode) ## comment to avoid the recomputation of weights\n",
    "\n",
    "iteration = 2000\n",
    "stabilise_in = 2\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data = (input, neigh, feature, ground)\n",
    "train(model, forward, data, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "Check the model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.        -1.7580993]]\n",
      "\n",
      " [[ 0.        -1.7580993]]\n",
      "\n",
      " [[ 0.        -1.7580993]]\n",
      "\n",
      " [[ 0.        -1.7580993]]], shape=(4, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = input\n",
    "for i in range(10):\n",
    "  result = forward(result, neigh, feature, model)\n",
    "print(result)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_dense_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqbsEJEnWOc7"
   },
   "source": [
    "# Check result, generalisation\n",
    "In this part, I try to use the same network in another graph, to see if it can be used in different graphs.\n",
    "\n",
    "## Linear network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LDTXF5knmGv",
    "outputId": "00d048a0-6c41-42d8-b33f-a721c8a66ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.         0.25339967]]\n",
      "\n",
      " [[0.         1.3921785 ]]\n",
      "\n",
      " [[0.         1.7501644 ]]\n",
      "\n",
      " [[0.         1.7997667 ]]\n",
      "\n",
      " [[0.         1.8072288 ]]], shape=(5, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0]\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n]\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, n, n, n], \n",
    "                     [1, n, 1, n, n],\n",
    "                     [n, 1, n, 1, n],\n",
    "                     [n, n, 1, n, 1],\n",
    "                     [n, n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states()\n",
    "for i in range(4):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50000\n",
    "feature_validation = tf.constant([\n",
    "                     [1], \n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                    ], dtype=tf.float32)\n",
    "output_validation = tf.constant([\n",
    "                     [0], \n",
    "                     [n],\n",
    "                     [n],\n",
    "                     [n],\n",
    "                    ], dtype=tf.float32)\n",
    "input_validation = tf.concat([feature_validation, output_validation], axis = 1)\n",
    "input_validation = input_validation[:,tf.newaxis, :]\n",
    "neigh_validation = tf.constant([\n",
    "                     [n, 1, 1, n], \n",
    "                     [1, n, n, 1],\n",
    "                     [1, n, n, 1],\n",
    "                     [n, 1, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "\n",
    "change_model = copy_model(model, mode, input_validation)\n",
    "\n",
    "result_validation = input_validation\n",
    "model.reset_states() ## if has recurrent layers\n",
    "for i in range(2):\n",
    "  result_validation = forward(result_validation, neigh_validation, feature_validation, change_model, False)\n",
    "print(result_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(tf.constant([[0, 100]]))) ## should be ~ 101\n",
    "print(model(tf.constant([[0, 10]]))) ## should be ~ 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced graph data\n",
    "In this case, we suppose to have a collective state that will evolve accordingly the node execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "feature_state = tf.constant([[1],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
    "output_state = tf.constant([[0],[n],[n],[n],[1],[2],[3],[4]], dtype=tf.float32)\n",
    "state = tf.constant([[0],[0],[0],[0],[0],[0],[0],[0]], dtype=tf.float32)\n",
    "#state = tf.random.uniform((8, 1), minval=0, maxval=1)\n",
    "\n",
    "input_state = tf.concat([feature_state, output_state, state], axis = 1)\n",
    "input_state = input_state[:,tf.newaxis, :]\n",
    "\n",
    "neigh_state = tf.constant([\n",
    "                     [n, 1, n, n, n, n, n, n],\n",
    "                     [1, n, 1, n, n, n, n, n],\n",
    "                     [n, 1, n, 1, n, n, n, n],\n",
    "                     [n, n, 1, n, n, n, n, n],\n",
    "                     [n, n, n, n, n, 1, n, n],\n",
    "                     [n, n, n, n, 1, n, 1, n],\n",
    "                     [n, n, n, n, n, 1, n, 1],\n",
    "                     [n, n, n, n, n, n, 1, n],\n",
    "                    ], dtype=tf.float32)\n",
    "ground_state = tf.constant([[0],[1],[2],[3],[n],[n],[n],[n]], dtype=tf.float32)\n",
    "## normalisation\n",
    "feature_state = feature_state / n\n",
    "output_state = output_state / n\n",
    "neigh_state = neigh_state / n\n",
    "ground_state = ground_state / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass rivisited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_state(result, neigh, feature, model_eval, log_enable=False):\n",
    "  input_shape_data = result[:, :, 1:]\n",
    "  if(log_enable):\n",
    "    print(\"Input = \", result)\n",
    "  old_output = tf.reshape(result[:,:, 1], feature.shape[0])\n",
    "  old_state = tf.reshape(result[:,:,2], feature.shape[0])\n",
    "  max_value = tf.reduce_max(neigh)\n",
    "  neigh_with_zero = tf.where(neigh == max_value, 0.0, 1.0)\n",
    "  neigh_output_evaluation = tf.reduce_min(tf.multiply(neigh, old_output), 1) ## pass reduction strategy\n",
    "  neigh_state_evaluation = tf.reduce_sum(tf.multiply(neigh_with_zero, old_state), 1) ## state evolution strategy\n",
    "  neigh_count = tf.reduce_sum(neigh_with_zero, 1)\n",
    "  neigh_state_evaluation = neigh_state_evaluation / neigh_count # mean\n",
    "  input_network = tf.concat([result[:,:, 0], neigh_output_evaluation[:, tf.newaxis], neigh_state_evaluation[:, tf.newaxis]], 1)\n",
    "  if(log_enable):\n",
    "    print(\"Neighbour Aggregation = \", input_network[:, tf.newaxis])\n",
    "  result = model_eval(input_network[:, tf.newaxis])\n",
    "  result = tf.reshape(result, (input_shape_data.shape[0], input_shape_data.shape[2])) ## adapt the shape in order to work both in linear model and in the recurrent model.\n",
    "  result = tf.concat([feature, result], axis = 1)\n",
    "  if(log_enable):\n",
    "    print(\"Output = \", result)\n",
    "  return tf.expand_dims(result, [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_0/assets\n",
      "Epoch  0 Loss =  0.00012473205\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_50/assets\n",
      "Epoch  50 Loss =  1.9936371\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_100/assets\n",
      "Epoch  100 Loss =  1.9600496\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_150/assets\n",
      "Epoch  150 Loss =  1.9328926\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_200/assets\n",
      "Epoch  200 Loss =  1.9059961\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_250/assets\n",
      "Epoch  250 Loss =  1.8758223\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_300/assets\n",
      "Epoch  300 Loss =  1.8369391\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_350/assets\n",
      "Epoch  350 Loss =  1.792875\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_400/assets\n",
      "Epoch  400 Loss =  1.7371259\n",
      "INFO:tensorflow:Assets written to: epoch/model_dense_450/assets\n",
      "Epoch  450 Loss =  2.6167297\n"
     ]
    }
   ],
   "source": [
    "#seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "#model_state = instatiate(input_state, mode, 2) ## comment to avoid the recomputation of weights\n",
    "model_state = tf.keras.models.load_model('epoch/best_fit_2')\n",
    "iteration = 500\n",
    "stabilise_in = 10\n",
    "stabilisation_check = 10\n",
    "\n",
    "loss = tf.losses.mse\n",
    "optimizer = tf.optimizers.Adam()\n",
    "data_state = (input_state, neigh_state, feature_state, ground_state)\n",
    "train(model_state, forward_with_state, data_state, iteration, stabilise_in, stabilisation_check, loss, optimizer, 50)\n",
    "model_state.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  1.         -1.4765141  10.341879 ]]\n",
      "\n",
      " [[  0.          2.2637596   9.631918 ]]\n",
      "\n",
      " [[  0.         18.646437   40.018635 ]]\n",
      "\n",
      " [[  0.          3.74054    16.039865 ]]\n",
      "\n",
      " [[  0.         72.02133   112.33399  ]]\n",
      "\n",
      " [[  0.         72.02133   112.33399  ]]\n",
      "\n",
      " [[  0.         72.02133   112.33399  ]]\n",
      "\n",
      " [[  0.         72.02133   112.33399  ]]], shape=(8, 1, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  0.]\n",
      " [  1.]\n",
      " [  2.]\n",
      " [  3.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]], shape=(8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = input_state\n",
    "for i in range(6):\n",
    "  result = forward_with_state(result, neigh_state, feature_state, model_state, False)\n",
    "print(result * n)\n",
    "print(ground_state * n)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9O5CIu3uDdkZ/uIe7V0gL",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "test-with-rnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
