{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "GNN_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cric96/DL-exercise/blob/main/GNN_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF0E71tLVoyn",
        "outputId": "951f3f23-ea04-4fde-a1ba-d9ef14247b57"
      },
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 1.x\n",
        "!pip install gnn\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gnn.GNN as GNN\n",
        "import gnn.gnn_utils\n",
        "import networkx as nx\n",
        "import scipy as sp\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting gnn\n",
            "  Downloading https://files.pythonhosted.org/packages/00/4d/f2ddea8ce94efad2b766aae9be49bc424fa36fa4e426473dd5e9dc00a15a/gnn-1.1.9-py3-none-any.whl\n",
            "Installing collected packages: gnn\n",
            "Successfully installed gnn-1.1.9\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gnn/GNN.py:7: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUZCmXM0hOxs"
      },
      "source": [
        "def weight_variable(shape, nm):\n",
        "    # function to initialize weights\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    tf.summary.histogram(nm, initial, collections=['always'])\n",
        "    return tf.Variable(initial, name=nm)\n",
        "\n",
        "\n",
        "class Net:\n",
        "    # class to define state and output network\n",
        "\n",
        "    def __init__(self, input_dim, state_dim, output_dim):\n",
        "        # initialize weight and parameter\n",
        "\n",
        "        self.EPSILON = 0.00000001\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.state_dim = state_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.state_input = self.input_dim - 1 + state_dim  # removing the id_ dimension\n",
        "\n",
        "        #### TO BE SET ON A SPECIFIC PROBLEM\n",
        "        self.state_l1 = 15\n",
        "        self.state_l2 = self.state_dim\n",
        "\n",
        "        self.output_l1 = 10\n",
        "        self.output_l2 = self.output_dim\n",
        "\n",
        "    def netSt(self, inp):\n",
        "        with tf.variable_scope('State_net'):\n",
        "            layer1 = tf.layers.dense(inp, self.state_l1, activation=tf.nn.tanh)\n",
        "            layer2 = tf.layers.dense(layer1, self.state_l2, activation=tf.nn.tanh)\n",
        "            return layer2\n",
        "\n",
        "    def netOut(self, inp):\n",
        "\n",
        "            layer1 = tf.layers.dense(inp, self.output_l1, activation=tf.nn.relu)\n",
        "            layer2 = tf.layers.dense(layer1, self.output_l2, activation=tf.nn.relu)\n",
        "\n",
        "            return layer2\n",
        "\n",
        "    def Loss(self, output, target, output_weight=None):\n",
        "        # method to define the loss function\n",
        "        #lo = tf.losses.softmax_cross_entropy(target, output)\n",
        "        output = tf.maximum(output, self.EPSILON, name=\"Avoiding_explosions\")  # to avoid explosions\n",
        "        xent = -tf.reduce_sum(target * tf.log(output), 1)\n",
        "        lo = tf.reduce_mean(xent)\n",
        "        return tf.losses.mean_squared_error(target, output)\n",
        "\n",
        "    def Metric(self, target, output, output_weight=None):\n",
        "        # method to define the evaluation metric\n",
        "        correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(target, 1))\n",
        "        metric = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        return metric"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWOsFxSHuwNj"
      },
      "source": [
        "# List of edges in the first graph - last column is the id of the graph to which the arc belongs\n",
        "def grid(row, column, graph):\n",
        "  result = []\n",
        "  for i in range(row - 1):\n",
        "    for j in range(column - 1):\n",
        "      index = (row * i) + j\n",
        "      next_on_column = index + 1\n",
        "      next_on_row = (row * (i + 1)) + j\n",
        "      result.append([index, next_on_column, graph])\n",
        "      result.append([index, next_on_row, graph])\n",
        "      result.append([index, next_on_row + 1, graph])\n",
        "  return result\n",
        "\n",
        "def neighbours(id, edges):\n",
        "  filtered = filter(lambda x: x[1] == id, edges)\n",
        "  mapped = map(lambda x: x[0], filtered)\n",
        "  return list(mapped)\n",
        "\n",
        "def hop_count(id, edges): \n",
        "  visited = set([id])\n",
        "  od = {}\n",
        "  hop = 0\n",
        "  od[id] = hop\n",
        "  to_visit = set(neighbours(id, edges))\n",
        "  while (len(to_visit) > 0):\n",
        "    visited = visited.union(to_visit)\n",
        "    hop += 1\n",
        "    next_visit = set([])\n",
        "    for id_neigh in to_visit:\n",
        "      od[id_neigh] = hop\n",
        "      next_visit = next_visit.union(set(neighbours(id_neigh, edges)))\n",
        "    to_visit = next_visit.difference(visited)\n",
        "  return dict(sorted(od.items(), key=lambda item: item[0]))\n",
        "\n",
        "# visualization graph\n",
        "def plot_graph(E, N, labels):\n",
        "    g = nx.Graph()\n",
        "    g.add_nodes_from(range(N.shape[0]))\n",
        "    g.add_edges_from(E[:, :2])\n",
        "    node_labels = dict(map(lambda kv: (kv[0], (kv[0], kv[1])), dict(enumerate(labels)).items()))\n",
        "    nx.draw_spring(g, cmap = plt.get_cmap('Set1'), labels = node_labels)\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klecIBWjVoyo"
      },
      "source": [
        "\n",
        "# Main file simple\n",
        "\n",
        "This is the main file for the simple classification task\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "bNrHZR-SVoyo",
        "outputId": "74d83e26-964f-45ee-da26-b5ff014c836e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import gnn.GNN as GNN\n",
        "import gnn.gnn_utils\n",
        "import networkx as nx\n",
        "import scipy as sp\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##### GPU & stuff config\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "############# data creation ################\n",
        "\n",
        "# GRAPH #\n",
        "\n",
        "row = 3\n",
        "column = 3\n",
        "#number of nodes\n",
        "edges = row * column\n",
        "e = grid(row, column, 0)\n",
        "# undirected graph, adding other direction\n",
        "e.extend([[i, j, num] for j, i, num in e])\n",
        "source_id = 3\n",
        "result = hop_count(source_id, e).items()\n",
        "labels = list(map(lambda x : x[1], result))\n",
        "\n",
        "#reorder\n",
        "e = sorted(e)\n",
        "E = np.asarray(e)\n",
        "\n",
        "# creating node features - simply one-hot values\n",
        "N = np.zeros((edges, edges), dtype=np.float32)\n",
        "N[source_id, source_id] = 1\n",
        "# adding column thta represent the id of the graph to which the node belongs\n",
        "N = np.concatenate((N, np.zeros((edges,1), dtype=np.float32)),  axis=1)\n",
        "\n",
        "plot_graph(E,N, labels)\n",
        "# GRAPH #2\n",
        "\n",
        "# List of edges in the second graph - last column graph-id\n",
        "e1 = grid(row, column, 1)\n",
        "# undirected graph, adding other direction\n",
        "e1.extend([[i, j, num] for j, i, num in e1])\n",
        "# reindexing node ids based on the dimension of previous graph (using unique ids)\n",
        "e2 = [[a + N.shape[0], b + N.shape[0], num] for a, b, num in e1]\n",
        "#reorder\n",
        "e2 = sorted(e2)\n",
        "\n",
        "# Plot second graph\n",
        "E1 = np.asarray(e1)\n",
        "N1 = np.zeros((edges, edges), dtype=np.float32)\n",
        "N1 = np.concatenate((N1, np.zeros((edges, 1), dtype=np.float32)),  axis=1)\n",
        "source_id = 5\n",
        "result = hop_count(source_id, e).items()\n",
        "labels1 = list(map(lambda x : x[1], result))\n",
        "\n",
        "labels = np.array(labels + labels1)\n",
        "\n",
        "N1[source_id, source_id] = 1\n",
        "plot_graph(E1, N1, labels1)\n",
        "\n",
        "# E = np.concatenate((E, np.asarray(e2)), axis=0)\n",
        "# N_tot = np.eye(edges + edges_2,  dtype=np.float32)\n",
        "# N_tot = np.concatenate((N_tot, np.zeros((edges + edges_2,1), dtype=np.float32)),  axis=1 )\n",
        "E = np.concatenate((E, np.asarray(e2)), axis=0)\n",
        "N_tot = np.eye(edges * 2,  dtype=np.float32)\n",
        "N_tot = np.concatenate((N_tot, np.zeros((edges * 2,1), dtype=np.float32)),  axis=1 )\n",
        "# Create Input to GNN\n",
        "inp, arcnode, graphnode = gnn.gnn_utils.from_EN_to_GNN(E, N_tot)\n",
        "# inp, arcnode, graphnode = gnn.gnn_utils.from_EN_to_GNN(E, N)\n",
        "labels = labels[..., None]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-389f29f88956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ConfigProto' object has no attribute 'reuse'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zIXnThGVoyp"
      },
      "source": [
        "## ###############################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sXIF8Ta3Voyq",
        "outputId": "d9984f40-978f-4b16-d537-23c859030426"
      },
      "source": [
        "# set input and output dim, the maximum number of iterations, the number of epochs and the optimizer\n",
        "threshold = 0.01\n",
        "learning_rate = 0.01\n",
        "state_dim = 3\n",
        "tf.reset_default_graph()\n",
        "input_dim = inp.shape[1]\n",
        "output_dim = labels.shape[1]\n",
        "print(input_dim)\n",
        "print(output_dim)\n",
        "max_it = row * column\n",
        "num_epoch = 1000\n",
        "optimizer = tf.train.AdamOptimizer\n",
        "\n",
        "# initialize state and output network\n",
        "net = Net(input_dim, state_dim, output_dim)\n",
        "# initialize GNN\n",
        "param = \"st_d\" + str(state_dim) + \"_th\" + str(threshold) + \"_lr\" + str(learning_rate)\n",
        "\n",
        "tensorboard = False\n",
        "\n",
        "g = GNN.GNN(net, input_dim, output_dim, state_dim,  max_it, optimizer, learning_rate, threshold, graph_based=False, param=param, config=config,\n",
        "            tensorboard=tensorboard)\n",
        "\n",
        "# train the model\n",
        "count = 0\n",
        "\n",
        "######\n",
        "\n",
        "for j in range(0, num_epoch):\n",
        "    _, it = g.Train(inputs=inp, ArcNode=arcnode, target=labels, step=count)\n",
        "\n",
        "    if count % 30 == 0:\n",
        "        print(\"Epoch \", count)\n",
        "        print(\"Training: \", g.Validate(inp, arcnode, labels, count))\n",
        "\n",
        "        # end = time.time()\n",
        "        # print(\"Epoch {} at time {}\".format(j, end-start))\n",
        "        # start = time.time()\n",
        "\n",
        "    count = count + 1\n",
        "\n",
        "# evaluate on the test set\n",
        "print(\"\\nEvaluate: \\n\")\n",
        "\n",
        "print(\"Training: \", g.Predict(inp, arcnode))\n",
        "print(\"Expected \", labels)\n",
        "\n",
        "#g = GNN.GNN(net, input_dim, output_dim, state_dim,  max_it, optimizer, learning_rate, threshold, graph_based=False, param=param, config=config, tensorboard=tensorboard)\n",
        "#number of nodes\n",
        "edges = row * column\n",
        "e = grid(row, column, 0)\n",
        "# undirected graph, adding other direction\n",
        "e.extend([[i, j, num] for j, i, num in e])\n",
        "source_id = 1\n",
        "result = hop_count(source_id, e).items()\n",
        "labels1 = np.array(list(map(lambda x : x[1], result)))\n",
        "\n",
        "#reorder\n",
        "e = sorted(e)\n",
        "E = np.asarray(e)\n",
        "\n",
        "# creating node features - simply one-hot values\n",
        "N = np.zeros((edges, edges), dtype=np.float32)\n",
        "N[source_id, source_id] = 1\n",
        "# adding column thta represent the id of the graph to which the node belongs\n",
        "N = np.concatenate((N, np.zeros((edges,1), dtype=np.float32)),  axis=1)\n",
        "\n",
        "inp1, arcnode1, graphnode1 = gnn.gnn_utils.from_EN_to_GNN(E, N)\n",
        "\n",
        "print(\"Training: \", g.Predict(inp1, arcnode1))\n",
        "print(\"Expected \", labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n",
            "Training:  (3.0179746, 1.0, 9)\n",
            "Epoch  30\n",
            "Training:  (0.48376513, 1.0, 9)\n",
            "Epoch  60\n",
            "Training:  (0.09562203, 1.0, 9)\n",
            "Epoch  90\n",
            "Training:  (0.03201969, 1.0, 9)\n",
            "Epoch  120\n",
            "Training:  (0.010088236, 1.0, 9)\n",
            "Epoch  150\n",
            "Training:  (0.0055572763, 1.0, 9)\n",
            "Epoch  180\n",
            "Training:  (0.0045848927, 1.0, 9)\n",
            "Epoch  210\n",
            "Training:  (0.0037399505, 1.0, 9)\n",
            "Epoch  240\n",
            "Training:  (0.0030462483, 1.0, 9)\n",
            "Epoch  270\n",
            "Training:  (0.0023724406, 1.0, 9)\n",
            "Epoch  300\n",
            "Training:  (0.0018404248, 1.0, 9)\n",
            "Epoch  330\n",
            "Training:  (0.0014057045, 1.0, 9)\n",
            "Epoch  360\n",
            "Training:  (0.0010571579, 1.0, 9)\n",
            "Epoch  390\n",
            "Training:  (0.00078296964, 1.0, 9)\n",
            "Epoch  420\n",
            "Training:  (0.00057119917, 1.0, 9)\n",
            "Epoch  450\n",
            "Training:  (0.00041051532, 1.0, 9)\n",
            "Epoch  480\n",
            "Training:  (0.0002906801, 1.0, 9)\n",
            "Epoch  510\n",
            "Training:  (0.00020280428, 1.0, 9)\n",
            "Epoch  540\n",
            "Training:  (0.00013942338, 1.0, 9)\n",
            "Epoch  570\n",
            "Training:  (9.444968e-05, 1.0, 9)\n",
            "Epoch  600\n",
            "Training:  (6.304819e-05, 1.0, 9)\n",
            "Epoch  630\n",
            "Training:  (4.1470958e-05, 1.0, 9)\n",
            "Epoch  660\n",
            "Training:  (2.6878168e-05, 1.0, 9)\n",
            "Epoch  690\n",
            "Training:  (1.7163928e-05, 1.0, 9)\n",
            "Epoch  720\n",
            "Training:  (1.079852e-05, 1.0, 9)\n",
            "Epoch  750\n",
            "Training:  (6.6927582e-06, 1.0, 9)\n",
            "Epoch  780\n",
            "Training:  (4.0860814e-06, 1.0, 9)\n",
            "Epoch  810\n",
            "Training:  (0.0001240182, 1.0, 9)\n",
            "Epoch  840\n",
            "Training:  (9.778592e-06, 1.0, 9)\n",
            "Epoch  870\n",
            "Training:  (7.333516e-06, 1.0, 9)\n",
            "Epoch  900\n",
            "Training:  (8.190784e-07, 1.0, 9)\n",
            "Epoch  930\n",
            "Training:  (4.167714e-07, 1.0, 9)\n",
            "Epoch  960\n",
            "Training:  (2.247313e-07, 1.0, 9)\n",
            "Epoch  990\n",
            "Training:  (1.2269473e-07, 1.0, 9)\n",
            "\n",
            "Evaluate: \n",
            "\n",
            "Training:  (array([[1.0000074e+00],\n",
            "       [2.0000024e+00],\n",
            "       [2.9999599e+00],\n",
            "       [0.0000000e+00],\n",
            "       [1.0000027e+00],\n",
            "       [2.0000029e+00],\n",
            "       [9.9999624e-01],\n",
            "       [1.0000021e+00],\n",
            "       [2.0000021e+00],\n",
            "       [1.9999964e+00],\n",
            "       [1.0000018e+00],\n",
            "       [1.9999976e+00],\n",
            "       [1.9999985e+00],\n",
            "       [9.9999475e-01],\n",
            "       [1.3546669e-03],\n",
            "       [2.9999719e+00],\n",
            "       [2.0000000e+00],\n",
            "       [1.9999976e+00]], dtype=float32), 9)\n",
            "Expected  [[1]\n",
            " [2]\n",
            " [3]\n",
            " [0]\n",
            " [1]\n",
            " [2]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [2]\n",
            " [2]\n",
            " [1]\n",
            " [0]\n",
            " [3]\n",
            " [2]\n",
            " [2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3c2238372aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphnode1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_EN_to_GNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcnode1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gnn/GNN.py\u001b[0m in \u001b[0;36mPredict\u001b[0;34m(self, inputs, ArcNode, nodegraph)\u001b[0m\n\u001b[1;32m    306\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_old\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mArcNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m               self.ArcNode: arcnode_}\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (24, 20) for Tensor 'input:0', which has shape '(?, 38)'"
          ]
        }
      ]
    }
  ]
}